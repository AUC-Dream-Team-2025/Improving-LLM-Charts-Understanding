{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Q_rjM3-B4MZ",
        "outputId": "c712820c-e3e9-40e0-90e6-86c886b66630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.8.0+cu129)\n",
            "Requirement already satisfied: pillow in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (11.2.1)\n",
            "Requirement already satisfied: tqdm in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.67.1)\n",
            "Requirement already satisfied: sentencepiece in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2025.9.18)\n",
            "Requirement already satisfied: requests in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.9.86 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (12.9.86)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.9.79 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (12.9.79)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.9.79 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (12.9.79)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.9.1.4 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (12.9.1.4)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.4.1.4 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (11.4.1.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.10.19 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (10.3.10.19)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.5.82 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (11.7.5.82)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.10.65 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (12.5.10.65)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.9.79 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (12.9.79)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.9.86 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (12.9.86)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.14.1.1 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (1.14.1.1)\n",
            "Requirement already satisfied: triton==3.4.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/g2/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2025.10.5)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch pillow tqdm sentencepiece\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IReh0piKB47E",
        "outputId": "41ca330d-fc92-4601-ffbf-7529b411aafa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Configuration and Setup\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# *** IMPORTANT: PLEASE UPDATE THESE PATHS ***\n",
        "IMAGE_DIR = \"/home/g2/Downloads/png\"\n",
        "# --- DATASET FILE PATHS ---\n",
        "# Cell 3: Configuration and Setup (This cell is correct, no changes)\n",
        "\n",
        "# --- DATASET FILE PATHS ---\n",
        "\n",
        "# 1. Base files (as .json containing a LIST)\n",
        "BASE_DATASET_FILES = {\n",
        "    \"human\": \"/home/g2/Downloads/test_human.json\",\n",
        "    \"augmented\": \"/home/g2/Downloads/test_augmented.json\"\n",
        "}\n",
        "\n",
        "# 2. DePlot files (as .jsonl)\n",
        "DEPLOT_DATA_FILES = {\n",
        "    \"human\": \"/home/g2/Downloads/deplot_human_output.jsonl\",\n",
        "    \"augmented\": \"/home/g2/Downloads/deplot_augmented_output.jsonl\"\n",
        "}\n",
        "\n",
        "# --- MODEL 1: MAIN QA MODEL (Pix2Struct) ---\n",
        "MAIN_MODEL_ID = \"google/pix2struct-base\"\n",
        "\n",
        "# --- MODEL 2: CHART CLASSIFIER (DinoV2) ---\n",
        "CLASSIFIER_MODEL_ID = \"/home/g2/Chart Classifier/chartqa-dinov2-finetuned\"\n",
        "CLASSIFIER_LABELS_PATH = \"/home/g2/Chart Classifier/labels.json\"\n",
        "\n",
        "\n",
        "# --- NEW COMBINED PROMPT TEMPLATE ---\n",
        "FINAL_COT_PROMPT = (\n",
        "    \"Let's think step by step to solve this problem.\\n\"\n",
        "    \"Here is the data from the chart, linearized into a table format:\\n\"\n",
        "    \"--- START OF CHART DATA ---\\n\"\n",
        "    \"{deplot_data}\\n\"\n",
        "    \"--- END OF CHART DATA ---\\n\\n\"\n",
        "    \"The image is a **{chart_type}**.\\n\\n\"\n",
        "    \"Using this chart data, chart type, AND the provided image, answer the following question.\\n\"\n",
        "    \"First, identify the relevant numbers from the provided chart data or the image. \"\n",
        "    \"Second, perform the necessary calculations. \"\n",
        "    \"Finally, state the final answer clearly.\\n\\n\"\n",
        "    \"Question: {question}\"\n",
        ")\n",
        "\n",
        "# --- Device Setup ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGAc3LlaCLAu",
        "outputId": "6bd443b2-0881-4c52-ed34-f6d4de4ade7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading main QA processor: google/pix2struct-base...\n",
            "Main processor loaded successfully.\n",
            "Loading main QA model: google/pix2struct-base...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Main QA model loaded successfully and set to eval mode.\n",
            "Loading classifier processor: /home/g2/Chart Classifier/chartqa-dinov2-finetuned...\n",
            "Classifier processor loaded successfully.\n",
            "Loading classifier model: /home/g2/Chart Classifier/chartqa-dinov2-finetuned...\n",
            "Classifier model loaded successfully and set to eval mode.\n",
            "Loading classifier labels: /home/g2/Chart Classifier/labels.json...\n",
            "Labels loaded successfully. Found 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Load BOTH Models, Processors, and Labels\n",
        "\n",
        "from transformers import (\n",
        "    Pix2StructProcessor, \n",
        "    Pix2StructForConditionalGeneration,\n",
        "    AutoImageProcessor, \n",
        "    AutoModelForImageClassification\n",
        ")\n",
        "\n",
        "# --- 1. Load Main QA Model (Pix2Struct) ---\n",
        "print(f\"Loading main QA processor: {MAIN_MODEL_ID}...\")\n",
        "try:\n",
        "    main_processor = Pix2StructProcessor.from_pretrained(MAIN_MODEL_ID)\n",
        "    print(\"Main processor loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading main processor: {e}\")\n",
        "    main_processor = None\n",
        "\n",
        "print(f\"Loading main QA model: {MAIN_MODEL_ID}...\")\n",
        "try:\n",
        "    main_model = Pix2StructForConditionalGeneration.from_pretrained(MAIN_MODEL_ID).to(device)\n",
        "    main_model.eval()\n",
        "    print(\"Main QA model loaded successfully and set to eval mode.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading main model: {e}\")\n",
        "    main_model = None\n",
        "\n",
        "# --- 2. Load Classifier Model (DinoV2) ---\n",
        "print(f\"Loading classifier processor: {CLASSIFIER_MODEL_ID}...\")\n",
        "try:\n",
        "    classifier_processor = AutoImageProcessor.from_pretrained(CLASSIFIER_MODEL_ID)\n",
        "    print(\"Classifier processor loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading classifier processor: {e}\")\n",
        "    classifier_processor = None\n",
        "\n",
        "print(f\"Loading classifier model: {CLASSIFIER_MODEL_ID}...\")\n",
        "try:\n",
        "    classifier_model = AutoModelForImageClassification.from_pretrained(CLASSIFIER_MODEL_ID).to(device)\n",
        "    classifier_model.eval()\n",
        "    print(\"Classifier model loaded successfully and set to eval mode.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading classifier model: {e}\")\n",
        "    classifier_model = None\n",
        "\n",
        "# --- 3. Load Classifier Labels ---\n",
        "print(f\"Loading classifier labels: {CLASSIFIER_LABELS_PATH}...\")\n",
        "try:\n",
        "    with open(CLASSIFIER_LABELS_PATH, \"r\") as f:\n",
        "        classifier_labels = json.load(f) # This is expected to be a list\n",
        "    print(f\"Labels loaded successfully. Found {len(classifier_labels)} classes.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Labels file not found at {CLASSIFIER_LABELS_PATH}\")\n",
        "    classifier_labels = None\n",
        "except Exception as e:\n",
        "    print(f\"Error loading labels file: {e}\")\n",
        "    classifier_labels = None\n",
        "\n",
        "# --- 4. Final Check ---\n",
        "if not all([main_processor, main_model, classifier_processor, classifier_model, classifier_labels]):\n",
        "    print(\"CRITICAL ERROR: Failed to load one or more components.\")\n",
        "    print(\"Please check all paths and file permissions. Evaluation cannot proceed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Viv8xKqNDkXK"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Helper Functions (CORRECTED)\n",
        "\n",
        "import json\n",
        "import os\n",
        "from decimal import Decimal\n",
        "\n",
        "# --- DATA LOADING FUNCTIONS ---\n",
        "\n",
        "def load_jsonl_file(filepath):\n",
        "    \"\"\"Loads a .jsonl file, returning a list of dictionaries.\"\"\"\n",
        "    data = []\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Error: File not found at {filepath}\")\n",
        "        return None\n",
        "    try:\n",
        "        with open(filepath, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    data.append(json.loads(line))\n",
        "        print(f\"Successfully loaded {len(data)} items from {filepath} (JSONL)\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_json_list_file(filepath):\n",
        "    \"\"\"Loads a .json file containing a single list.\"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Error: File not found at {filepath}\")\n",
        "        return None\n",
        "    try:\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        if not isinstance(data, list):\n",
        "            print(f\"Error: File {filepath} does not contain a JSON list.\")\n",
        "            return None\n",
        "        print(f\"Successfully loaded {len(data)} items from {filepath} (JSON List)\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def merge_datasets(base_data, deplot_data_list):\n",
        "    \"\"\"\n",
        "    Performs a 1-to-1 parallel merge of two datasets.\n",
        "    \"\"\"\n",
        "    if len(base_data) != len(deplot_data_list):\n",
        "        print(f\"Error: Mismatch in dataset lengths. Base data has {len(base_data)} items, DePlot has {len(deplot_data_list)}.\")\n",
        "        return []\n",
        "    \n",
        "    print(f\"Performing 1-to-1 parallel merge on {len(base_data)} items...\")\n",
        "    merged_data = []\n",
        "    \n",
        "    for i in range(len(base_data)):\n",
        "        base_item = base_data[i]\n",
        "        deplot_item = deplot_data_list[i]\n",
        "        \n",
        "        # Start with all data from the base file (imgname, query, label)\n",
        "        merged_item = base_item.copy()\n",
        "        \n",
        "        # --- THIS IS THE FIX ---\n",
        "        # Look for \"deplot_table\" from your .jsonl file\n",
        "        if \"deplot_table\" in deplot_item:\n",
        "            merged_item[\"deplot_data\"] = deplot_item[\"deplot_table\"] # Create a new key \"deplot_data\"\n",
        "        else:\n",
        "            merged_item[\"deplot_data\"] = None\n",
        "            print(f\"Warning: 'deplot_table' key missing for item {i} (imgname: {base_item.get('imgname')}).\")\n",
        "        # -----------------------\n",
        "\n",
        "        merged_data.append(merged_item)\n",
        "        \n",
        "    print(f\"Successfully merged {len(merged_data)} items.\")\n",
        "    return merged_data\n",
        "\n",
        "# --- ACCURACY FUNCTION ---\n",
        "\n",
        "def calculate_relaxed_accuracy(prediction_str, ground_truth_str):\n",
        "    \"\"\"\n",
        "    Calculates \"relaxed\" accuracy.\n",
        "    \"\"\"\n",
        "    prediction_str = str(prediction_str).strip().lower()\n",
        "    ground_truth_str = str(ground_truth_str).strip().lower()\n",
        "\n",
        "    if prediction_str == ground_truth_str:\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        pred_num = Decimal(prediction_str)\n",
        "        gt_num = Decimal(ground_truth_str)\n",
        "        if pred_num == gt_num:\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dL0v8ykvfPct"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Evaluation Function (CORRECTED)\n",
        "\n",
        "def evaluate_model(\n",
        "    main_model, main_processor, \n",
        "    classifier_model, classifier_processor, classifier_labels,\n",
        "    dataset, image_dir, dataset_name=\"evaluation\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs the full evaluation pipeline with all correct keys.\n",
        "    \"\"\"\n",
        "    \n",
        "    if not all([main_processor, main_model, classifier_processor, classifier_model, classifier_labels]):\n",
        "        print(f\"Skipping evaluation for {dataset_name}: Not all components are loaded.\")\n",
        "        return 0.0\n",
        "\n",
        "    progress_file = f\"evaluation_progress_{dataset_name}.jsonl\"\n",
        "    processed_imgnames = set()\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    # 1. Load existing progress\n",
        "    if os.path.exists(progress_file):\n",
        "        try:\n",
        "            with open(progress_file, 'r') as f:\n",
        "                for line in f:\n",
        "                    if line.strip():\n",
        "                        data = json.loads(line)\n",
        "                        processed_imgnames.add(data['imgname'])\n",
        "                        if data['is_correct']:\n",
        "                            total_correct += 1\n",
        "                        total_predictions += 1\n",
        "            print(f\"Resuming from {total_predictions} processed items for {dataset_name}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading progress file {progress_file}: {e}. Starting fresh.\")\n",
        "            processed_imgnames = set()\n",
        "            total_correct = 0\n",
        "            total_predictions = 0\n",
        "\n",
        "    print(f\"Starting evaluation... {total_predictions}/{len(dataset)} items already processed.\")\n",
        "\n",
        "    # 2. Loop through remaining items\n",
        "    try:\n",
        "        with open(progress_file, 'a') as f_progress:\n",
        "            for item in tqdm(dataset, desc=f\"Evaluating {dataset_name}\"):\n",
        "                try:\n",
        "                    imgname = item['imgname']\n",
        "                    if imgname in processed_imgnames:\n",
        "                        continue \n",
        "\n",
        "                    # --- THIS IS THE FIX ---\n",
        "                    # Use the correct keys from your data files\n",
        "                    ground_truth_str = str(item['label'])\n",
        "                    question = item['query'] \n",
        "                    deplot_data = item['deplot_data'] # This key is created by our merge function\n",
        "                    # -----------------------\n",
        "                    \n",
        "                    image_path = os.path.join(image_dir, imgname)\n",
        "                    \n",
        "                    if deplot_data is None:\n",
        "                        print(f\"Skipping {imgname}: 'deplot_table' was missing from .jsonl file.\")\n",
        "                        continue\n",
        "\n",
        "                    # 2. Load image\n",
        "                    try:\n",
        "                        image = Image.open(image_path).convert(\"RGB\")\n",
        "                    except FileNotFoundError:\n",
        "                        print(f\"Warning: Image file not found {image_path}. Skipping item.\")\n",
        "                        continue\n",
        "                    \n",
        "                    # 3. PIPELINE STEP 1: CLASSIFY CHART TYPE\n",
        "                    clf_inputs = classifier_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "                    with torch.no_grad():\n",
        "                        logits = classifier_model(**clf_inputs).logits\n",
        "                        pred_id = logits.argmax(-1).item()\n",
        "                    predicted_chart_type = classifier_labels[pred_id]\n",
        "                    \n",
        "                    # 4. PIPELINE STEP 2: FORMAT PROMPT\n",
        "                    formatted_prompt = FINAL_COT_PROMPT.format(\n",
        "                        deplot_data=deplot_data,\n",
        "                        chart_type=predicted_chart_type,\n",
        "                        question=question\n",
        "                    )\n",
        "                    \n",
        "                    # 5. PIPELINE STEP 3: RUN MAIN QA MODEL\n",
        "                    inputs = main_processor(images=image, text=formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "                    with torch.no_grad():\n",
        "                        generated_ids = main_model.generate(**inputs, max_new_tokens=512)\n",
        "                    \n",
        "                    generated_text = main_processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "                    # 6. CALCULATE ACCURACY\n",
        "                    is_correct = calculate_relaxed_accuracy(generated_text, ground_truth_str)\n",
        "                    \n",
        "                    if is_correct:\n",
        "                        total_correct += 1\n",
        "                    total_predictions += 1\n",
        "                    \n",
        "                    # 7. SAVE PROGRESS\n",
        "                    result_record = {\n",
        "                        \"imgname\": imgname,\n",
        "                        \"used_prompt\": formatted_prompt,\n",
        "                        \"predicted_chart_type\": predicted_chart_type,\n",
        "                        \"prediction_qa\": generated_text,\n",
        "                        \"ground_truth_qa\": ground_truth_str,\n",
        "                        \"is_correct\": is_correct\n",
        "                    }\n",
        "                    f_progress.write(json.dumps(result_record) + \"\\n\")\n",
        "                    f_progress.flush()\n",
        "                    \n",
        "                    processed_imgnames.add(imgname)\n",
        "\n",
        "                except KeyError as e:\n",
        "                    print(f\"Skipping {item.get('imgname')}: Missing expected data key: {e}\")\n",
        "                    continue\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during evaluation for item {item.get('imgname')}: {e}\")\n",
        "                    continue\n",
        "                    \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Evaluation interrupted by user. Progress saved.\")\n",
        "\n",
        "    # 8. Final Accuracy Calculation\n",
        "    if total_predictions == 0:\n",
        "        print(\"No items were processed.\")\n",
        "        return 0.0\n",
        "\n",
        "    accuracy = (total_correct / total_predictions) * 100\n",
        "    print(f\"Evaluation complete for {dataset_name}.\")\n",
        "    print(f\"Processed: {total_predictions} items.\")\n",
        "    print(f\"Correct: {total_correct}\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x61Y02RUfTjJ",
        "outputId": "84d09a7e-adf4-4ecc-9722-b1290d8cca48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Evaluation ---\n",
            "\n",
            "Loading dataset: human\n",
            "Successfully loaded 1250 items from /home/g2/Downloads/test_human.json (JSON List)\n",
            "Successfully loaded 1250 items from /home/g2/Downloads/deplot_human_output.jsonl (JSONL)\n",
            "Merging human dataset...\n",
            "Performing 1-to-1 parallel merge on 1250 items...\n",
            "Successfully merged 1250 items.\n",
            "Dataset human loaded with 1250 items.\n",
            "\n",
            "Loading dataset: augmented\n",
            "Successfully loaded 1250 items from /home/g2/Downloads/test_augmented.json (JSON List)\n",
            "Successfully loaded 1250 items from /home/g2/Downloads/deplot_augmented_output.jsonl (JSONL)\n",
            "Merging augmented dataset...\n",
            "Performing 1-to-1 parallel merge on 1250 items...\n",
            "Successfully merged 1250 items.\n",
            "Dataset augmented loaded with 1250 items.\n",
            "\n",
            "--- All Models and Data Loaded, Starting Pipeline Inference ---\n",
            "\n",
            "--- Evaluating: HUMAN ---\n",
            "Resuming from 0 processed items for human...\n",
            "Starting evaluation... 0/1250 items already processed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating human: 100%|██████████| 1250/1250 [2:30:19<00:00,  7.22s/it] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation complete for human.\n",
            "Processed: 625 items.\n",
            "Correct: 0\n",
            "Accuracy: 0.00%\n",
            "\n",
            "--- Evaluating: AUGMENTED ---\n",
            "Resuming from 0 processed items for augmented...\n",
            "Starting evaluation... 0/1250 items already processed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating augmented:   2%|▏         | 20/1250 [03:26<3:31:32, 10.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation interrupted by user. Progress saved.\n",
            "Evaluation complete for augmented.\n",
            "Processed: 11 items.\n",
            "Correct: 0\n",
            "Accuracy: 0.00%\n",
            "\n",
            "--- Evaluation Finished ---\n",
            "Final Accuracies (with Chart Classifier + Detailed CoT Prompt):\n",
            "{\n",
            "  \"human\": 0.0,\n",
            "  \"augmented\": 0.0\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Run Evaluation (CORRECTED)\n",
        "\n",
        "print(\"--- Starting Evaluation ---\")\n",
        "accuracies = {}\n",
        "\n",
        "# 1. Load datasets\n",
        "datasets = {}\n",
        "for name in BASE_DATASET_FILES.keys():\n",
        "    print(f\"\\nLoading dataset: {name}\")\n",
        "    base_data = load_json_list_file(BASE_DATASET_FILES[name])\n",
        "    deplot_data = load_jsonl_file(DEPLOT_DATA_FILES[name])\n",
        "    \n",
        "    if base_data is None or deplot_data is None:\n",
        "        print(f\"Failed to load data for {name}. Skipping.\")\n",
        "        continue\n",
        "        \n",
        "    print(f\"Merging {name} dataset...\")\n",
        "    merged_data = merge_datasets(base_data, deplot_data)\n",
        "    \n",
        "    if merged_data:\n",
        "        # --- THIS IS THE FIX ---\n",
        "        # Filter for items that have a \"query\" key\n",
        "        filtered_data = [item for item in merged_data if item.get(\"query\")]\n",
        "        # -----------------------\n",
        "        \n",
        "        datasets[name] = filtered_data\n",
        "        print(f\"Dataset {name} loaded with {len(filtered_data)} items.\") # <-- This will now be > 0\n",
        "    else:\n",
        "        print(f\"Failed to merge dataset {name}.\")\n",
        "\n",
        "print(\"\\n--- All Models and Data Loaded, Starting Pipeline Inference ---\")\n",
        "\n",
        "# 2. Run evaluation on each loaded dataset\n",
        "for dataset_name, dataset in datasets.items():\n",
        "    print(f\"\\n--- Evaluating: {dataset_name.upper()} ---\")\n",
        "    \n",
        "    if not dataset:\n",
        "        print(\"Dataset is empty. Skipping.\")\n",
        "        accuracies[dataset_name] = 0.0\n",
        "        continue\n",
        "        \n",
        "    acc = evaluate_model(\n",
        "        main_model=main_model,\n",
        "        main_processor=main_processor,\n",
        "        classifier_model=classifier_model,\n",
        "        classifier_processor=classifier_processor,\n",
        "        classifier_labels=classifier_labels,\n",
        "        dataset=dataset,\n",
        "        image_dir=IMAGE_DIR,\n",
        "        dataset_name=dataset_name\n",
        "    )\n",
        "    accuracies[dataset_name] = acc\n",
        "\n",
        "print(\"\\n--- Evaluation Finished ---\")\n",
        "print(\"Final Accuracies (with Chart Classifier + Detailed CoT Prompt):\")\n",
        "print(json.dumps(accuracies, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "M_-j-Bb2fVRM",
        "outputId": "951cd758-b686-4e43-9f82-dfab28228800"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 8: Plot Results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Use the 'results' dictionary generated in the previous cell\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# No need to load from progress file again\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresults\u001b[49m:\n\u001b[1;32m      7\u001b[0m     names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(results\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      8\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(results\u001b[38;5;241m.\u001b[39mvalues())\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "# Cell 8: Plot Results\n",
        "\n",
        "# Use the 'results' dictionary generated in the previous cell\n",
        "# No need to load from progress file again\n",
        "\n",
        "if results:\n",
        "    names = list(results.keys())\n",
        "    values = list(results.values())\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    # Define colors for different datasets if needed, e.g., {'human': '#4A90E2', 'augmented': '#FF6B6B'}\n",
        "    colors = ['#4A90E2' for _ in names] # Default to blue for all if no specific colors defined\n",
        "\n",
        "    bars = plt.bar(names, values, color=colors)\n",
        "\n",
        "    plt.xlabel(\"Dataset Type\", fontsize=12)\n",
        "    plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
        "    # Update title to reflect that it might be complete or partial based on the previous cell's run\n",
        "    plt.title(f\"Model Accuracy: (with DePlot + CoT) - {'Complete' if all(name in results for name in BASE_DATASET_FILES.keys()) else 'Partial'} Results\", fontsize=14)\n",
        "    plt.ylim(0, 100)\n",
        "\n",
        "    # Add accuracy numbers on top of bars\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1, f'{yval:.2f}%', ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No results available to plot.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.10.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
