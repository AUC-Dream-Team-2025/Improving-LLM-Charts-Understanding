{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821017d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f673c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba8d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g2/Chart2Table Client/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Chart Understanding with Qwen2.5-VL-7B-Instruct\n",
      "ENHANCED VERSION - With Chart2Table Chain Strategy\n",
      "============================================================\n",
      "\n",
      "[1/3] Initializing Qwen model...\n",
      "Loading model: Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.36it/s]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "[2/3] Loading benchmark dataset...\n",
      "Loaded existing benchmark with 2500 examples\n",
      "\n",
      "[3/3] Running comprehensive evaluation...\n",
      "Testing with all 2500 samples\n",
      "\n",
      "✅ Testing only these strategies: ['chart2table_chain', 'chart2table_cot']\n",
      "\n",
      "============================================================\n",
      "Initializing Chart2Table model for Chart2Table-based strategies...\n",
      "============================================================\n",
      "Initializing Chart Extractor (PaddlePaddle API Client)...\n",
      "✓ Connected to PaddlePaddle API at http://localhost:8000\n",
      "  Response: {'status': 'healthy', 'service': 'PaddlePaddle Chart2Table API'}\n",
      "\n",
      "============================================================\n",
      "Testing Strategy: CHART2TABLE_CHAIN\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_chain:   0%|          | 1/2500 [00:05<3:59:11,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1 ---\n",
      "Question: How many food item is shown in the bar graph?\n",
      "Chart2Table Table: Country | Long-term price index in food commodities, 1850-2015, World, 1934 Lamb | 103.7 Corn | 103.13 Barley | 102.46 Rye | 87.37 Beef | 85.27 Wheat ...\n",
      "Predicted: The bar graph shows 15 different food items. Each item is represented by a horizontal bar with a corresponding label and value.\n",
      "\n",
      "Final Answer: 15\n",
      "Ground Truth: ['14']\n",
      "Correct: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_chain:   0%|          | 2/2500 [00:12<4:23:37,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 2 ---\n",
      "Question: What is the difference in value between Lamb and Corn?\n",
      "Chart2Table Table: Country | Long-term price index in food commodities, 1850-2015, World, 1934 Lamb | 103.7 Corn | 103.13 Barley | 102.46 Rye | 87.37 Beef | 85.27 Wheat ...\n",
      "Predicted: To find the difference in value between Lamb and Corn, we need to subtract the value of Corn from the value of Lamb.\n",
      "\n",
      "From the table:\n",
      "- Lamb = 103.7\n",
      "- Corn = 103.13\n",
      "\n",
      "Difference = Lamb - Corn\n",
      "           = 103.7 - 103.13\n",
      "           = 0.57\n",
      "\n",
      "Final Answer: 0.57\n",
      "Ground Truth: ['0.57']\n",
      "Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_chain:   0%|          | 3/2500 [00:14<3:06:55,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 3 ---\n",
      "Question: How many bars are shown in the chart?\n",
      "Chart2Table Table: Characteristic | Value Mauritania | 0.48% Fiji | 0.38% Madagascar | 0.21%...\n",
      "Predicted: The chart shows three bars, each representing a different country: Mauritania, Fiji, and Madagascar. The bars are color-coded and have corresponding percentages next to them.\n",
      "\n",
      "Final Answer: 3\n",
      "Ground Truth: ['3']\n",
      "Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_chain: 100%|██████████| 2500/2500 [4:07:52<00:00,  5.95s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for chart2table_chain:\n",
      "  Accuracy: 86.28% (2157/2500)\n",
      "  Avg Inference Time: 2.77s\n",
      "  Avg Total Time (Chart2Table + Qwen): 5.95s\n",
      "\n",
      "============================================================\n",
      "Testing Strategy: CHART2TABLE_COT\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot:   0%|          | 1/2500 [00:10<7:02:31, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1 ---\n",
      "Question: How many food item is shown in the bar graph?\n",
      "Chart2Table Table: Country | Long-term price index in food commodities, 1850-2015, World, 1934 Lamb | 103.7 Corn | 103.13 Barley | 102.46 Rye | 87.37 Beef | 85.27 Wheat ...\n",
      "Predicted: 1. **Understand the Question:**\n",
      "   - The question asks how many food items are shown in the bar graph.\n",
      "\n",
      "2. **Analyze the Chart Visually:**\n",
      "   - The chart is a horizontal bar graph.\n",
      "   - The x-axis represents the long-term price index values.\n",
      "   - The y-axis lists different food items.\n",
      "   - There are 15 distinct bars, each representing a different food item.\n",
      "\n",
      "3. **Cross-Reference with Table Data:**\n",
      "   - The table data confirms that there are 15 entries, each corresponding to a food item.\n",
      "   - Each entry matches the labels on the y-axis of the chart.\n",
      "\n",
      "4. **Perform Calculations (if needed):**\n",
      "   - No calculations are necessary as the number of food items is directly visible in the chart and confirmed by the table data.\n",
      "\n",
      "5. **Verify Your Answer:**\n",
      "   - Both the chart and the table show 15 food items.\n",
      "   - The visual count of bars matches the count of entries in the table.\n",
      "\n",
      "6. **Provide Final Answer:**\n",
      "   - Final Answer: 15\n",
      "Ground Truth: ['14']\n",
      "Correct: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot:   0%|          | 2/2500 [00:20<7:09:51, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 2 ---\n",
      "Question: What is the difference in value between Lamb and Corn?\n",
      "Chart2Table Table: Country | Long-term price index in food commodities, 1850-2015, World, 1934 Lamb | 103.7 Corn | 103.13 Barley | 102.46 Rye | 87.37 Beef | 85.27 Wheat ...\n",
      "Predicted: 1. **Understand the Question:**\n",
      "   - The question asks for the difference in value between Lamb and Corn.\n",
      "\n",
      "2. **Analyze the Chart Visually:**\n",
      "   - This is a horizontal bar chart.\n",
      "   - The x-axis represents the long-term price index values.\n",
      "   - The y-axis lists different food commodities.\n",
      "   - Lamb has the highest value at 103.7, and Corn has the second-highest value at 103.13.\n",
      "\n",
      "3. **Cross-Reference with Table Data:**\n",
      "   - From the table, Lamb's value is 103.7.\n",
      "   - From the table, Corn's value is 103.13.\n",
      "   - Both values match the chart visually.\n",
      "\n",
      "4. **Perform Calculations:**\n",
      "   - Calculate the difference: 103.7 - 103.13 = 0.57\n",
      "\n",
      "5. **Verify Your Answer:**\n",
      "   - The difference is consistent across the chart and the table.\n",
      "   - The calculation is straightforward and correct.\n",
      "\n",
      "6. **Provide Final Answer:**\n",
      "   - Final Answer: 0.57\n",
      "Ground Truth: ['0.57']\n",
      "Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot:   0%|          | 3/2500 [00:28<6:25:15,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 3 ---\n",
      "Question: How many bars are shown in the chart?\n",
      "Chart2Table Table: Characteristic | Value Mauritania | 0.48% Fiji | 0.38% Madagascar | 0.21%...\n",
      "Predicted: 1. **Understand the Question:**\n",
      "   - The question asks how many bars are shown in the chart.\n",
      "   - This requires identifying the number of distinct categories represented in the chart.\n",
      "\n",
      "2. **Analyze the Chart Visually:**\n",
      "   - The chart is a horizontal bar chart.\n",
      "   - There are three horizontal bars, each representing a different country: Mauritania, Fiji, and Madagascar.\n",
      "   - Each bar has a corresponding percentage value at the end.\n",
      "\n",
      "3. **Cross-Reference with Table Data:**\n",
      "   - From the table, we have:\n",
      "     - Mauritania: 0.48%\n",
      "     - Fiji: 0.38%\n",
      "     - Madagascar: 0.21%\n",
      "   - These percentages correspond to the lengths of the bars in the chart.\n",
      "   - The table confirms that there are three distinct categories.\n",
      "\n",
      "4. **Perform Calculations (if needed):**\n",
      "   - No calculations are necessary here as the number of bars is visually evident and confirmed by the table data.\n",
      "\n",
      "5. **Verify Your Answer:**\n",
      "   - The chart shows three distinct horizontal bars.\n",
      "   - The table data lists three countries with their respective percentages.\n",
      "   - Both the visual and tabular data confirm the presence of three bars.\n",
      "\n",
      "6. **Provide Final Answer:**\n",
      "   - Final Answer: 3\n",
      "Ground Truth: ['3']\n",
      "Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot: 100%|██████████| 2500/2500 [8:44:58<00:00, 12.60s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for chart2table_cot:\n",
      "  Accuracy: 93.96% (2349/2500)\n",
      "  Avg Inference Time: 9.39s\n",
      "  Avg Total Time (Chart2Table + Qwen): 12.60s\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "chart2table_chain   : 86.28%\n",
      "chart2table_cot     : 93.96%\n",
      "\n",
      "Results saved to results_whole_with_chart2table.json\n",
      "\n",
      "✅ Evaluation complete!\n",
      "Check 'results_whole_with_chart2table.json' for detailed results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Chart Understanding with Qwen2.5-VL-7B-Instruct\n",
    "Graduation Project - Prompting Techniques Evaluation\n",
    "ENHANCED VERSION: Added Chart2Table Chain-of-Models Strategy + Strategy Selection\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# QUICK CONFIGURATION - Modify these before running!\n",
    "# ============================================================================\n",
    "# To test with 100 examples: Set NUM_SAMPLES = 100\n",
    "# To test with full dataset: Set NUM_SAMPLES = None\n",
    "# See main() function for more configuration options\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "import base64\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\n",
    "from qwen_vl_utils import process_vision_info  # REQUIRED: pip install qwen-vl-utils\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "class Config:\n",
    "\n",
    "    # GPU Memory Management\n",
    "    GPU_MEMORY_FRACTION = 0.75  # Use 75% of remaining GPU memory\n",
    "    ENABLE_TF32 = True  # Faster computation on Ampere+ GPUs\n",
    "\n",
    "    # LLM (PyTorch - same as before)\n",
    "    LLM_MODEL = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "    DATASET = \"jrc/cleaned-plotqa-v2\"\n",
    "    OUTPUT_DIR = \"plotqa_safe_solver_cot_sc_v2\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # PaddlePaddle API Server (microservice)\n",
    "    PADDLE_API_URL = \"http://localhost:8000\"  # Change if running on different machine\n",
    "    PADDLE_API_TIMEOUT = 30  # seconds\n",
    "\n",
    "    # Token limits\n",
    "    MAX_INPUT_TOKENS = 4096\n",
    "    MAX_NEW_TOKENS = 128\n",
    "\n",
    "    # CoT + Self-Consistency\n",
    "    USE_COT = True\n",
    "    FEW_SHOT_COT = True\n",
    "    SC_SAMPLES = 5\n",
    "    TEMP_COT = 0.7\n",
    "    TOP_P_COT = 0.95\n",
    "\n",
    "    # Debug\n",
    "    VERBOSE_DEBUG = False\n",
    "\n",
    "# ================================================================\n",
    "# CHART EXTRACTOR: CALLS PADDLEPADDLE API INSTEAD OF LOCAL MODEL\n",
    "# ================================================================\n",
    "\n",
    "class ChartExtractor:\n",
    "    \"\"\"Client for PaddlePaddle Chart2Table API\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Initializing Chart Extractor (PaddlePaddle API Client)...\")\n",
    "        self.api_url = Config.PADDLE_API_URL\n",
    "        self.timeout = Config.PADDLE_API_TIMEOUT\n",
    "        \n",
    "        # Check if API is available\n",
    "        try:\n",
    "            response = requests.get(f\"{self.api_url}/health\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"✓ Connected to PaddlePaddle API at {self.api_url}\")\n",
    "                print(f\"  Response: {response.json()}\")\n",
    "            else:\n",
    "                raise Exception(f\"API returned status {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to connect to PaddlePaddle API at {self.api_url}\")\n",
    "            print(f\"  Error: {e}\")\n",
    "            print(f\"  Make sure the API server is running:\")\n",
    "            print(f\"    uvicorn paddle_api_server:app --host 0.0.0.0 --port 8000\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def extract_table(self, image_input) -> str:\n",
    "        \"\"\"Extract table from image by calling the PaddlePaddle API\n",
    "        \n",
    "        Args:\n",
    "            image_input: Either a PIL Image object or a string path to image file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ✅ Handle both PIL Image and string path\n",
    "            if isinstance(image_input, str):\n",
    "                from PIL import Image\n",
    "                image = Image.open(image_input)\n",
    "            else:\n",
    "                image = image_input\n",
    "            \n",
    "            # Convert image to base64\n",
    "            img_buffer = io.BytesIO()\n",
    "            image.save(img_buffer, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(img_buffer.getvalue()).decode(\"utf-8\")\n",
    "            \n",
    "            # Call API\n",
    "            response = requests.post(\n",
    "                f\"{self.api_url}/extract-base64\",\n",
    "                json={\"image_base64\": img_base64},\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                raise Exception(f\"API error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "            result = response.json()\n",
    "            \n",
    "            if not result.get(\"success\"):\n",
    "                raise Exception(f\"API returned failure: {result}\")\n",
    "            \n",
    "            # Return cleaned table\n",
    "            return result[\"table_clean\"]\n",
    "        \n",
    "        except requests.exceptions.Timeout:\n",
    "            raise Exception(f\"API request timed out (>{self.timeout}s). Check server status.\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            raise Exception(f\"Cannot connect to PaddlePaddle API at {self.api_url}. Is server running?\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error extracting chart: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL SETUP (FROM FIRST CODE - CORRECT IMPLEMENTATION)\n",
    "# ============================================================================\n",
    "\n",
    "class ChartAnalyzer:\n",
    "    \"\"\"Main class for chart analysis using Qwen2.5-VL-7B-Instruct\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = \"Qwen/Qwen2.5-VL-7B-Instruct\"):\n",
    "        print(f\"Loading model: {model_path}\")\n",
    "        \n",
    "        # ✅ NEW: Limit GPU memory usage BEFORE loading model\n",
    "        # Set GPU memory fraction\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.set_per_process_memory_fraction(Config.GPU_MEMORY_FRACTION, 0)\n",
    "            # Enable TF32 for faster computation (Ampere+ GPUs)\n",
    "            if Config.ENABLE_TF32:\n",
    "                torch.backends.cuda.matmul.allow_tf32 = True\n",
    "                torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "        # Load model\n",
    "        self.model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        # Load processor\n",
    "        self.processor = AutoProcessor.from_pretrained(\n",
    "            model_path,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        \n",
    "    def generate_response(\n",
    "        self, \n",
    "        image_path: str, \n",
    "        prompt: str,\n",
    "        max_new_tokens: int = 512,\n",
    "        temperature: float = 0.1,  # Lower temperature for factual chart tasks\n",
    "        top_p: float = 0.9,\n",
    "        few_shot_messages: List[Dict] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate response for a given image and prompt\n",
    "        Uses official Qwen implementation with qwen_vl_utils\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the chart image\n",
    "            prompt: Text prompt for the model\n",
    "            max_new_tokens: Maximum tokens to generate\n",
    "            temperature: Sampling temperature (lower = more factual)\n",
    "            top_p: Top-p sampling parameter\n",
    "            few_shot_messages: Optional pre-built message history for multimodal few-shot\n",
    "            \n",
    "        Returns:\n",
    "            Generated text response\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Construct Messages\n",
    "        messages = []\n",
    "        \n",
    "        # Add few-shot history if present\n",
    "        if few_shot_messages:\n",
    "            messages.extend(few_shot_messages)\n",
    "            \n",
    "        # Add current query\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image_path},  # CORRECT: use 'image' key\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        # 2. Prepare Inputs (The Official Qwen Way)\n",
    "        text = self.processor.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        \n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Move inputs to GPU\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        \n",
    "        # 3. Generate\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                do_sample=temperature > 0\n",
    "            )\n",
    "        \n",
    "        # 4. Decode - Trim input tokens from output\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        \n",
    "        response_text = self.processor.batch_decode(\n",
    "            generated_ids_trimmed, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "        \n",
    "        return response_text\n",
    "\n",
    "\n",
    "def clean_chart2text_output(table_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans raw Chart2Table output into a readable format for the LLM.\n",
    "    \"\"\"\n",
    "    # 1. Replace the hex newline with a real newline\n",
    "    cleaned = table_text.replace(\"<0x0A>\", \"\\n\")\n",
    "    \n",
    "    # 2. Replace hex tab with a pipe (if it exists)\n",
    "    cleaned = cleaned.replace(\"<0x09>\", \" | \")\n",
    "    \n",
    "    # 3. Ensure pipes have spaces for better tokenization\n",
    "    # This handles cases like \"Apple|5\" becoming \"Apple | 5\"\n",
    "    cleaned = cleaned.replace(\"|\", \" | \")\n",
    "    \n",
    "    # 4. Remove multiple spaces created by step 3\n",
    "    # (e.g., if it was already \" | \", step 3 makes it \"  |  \")\n",
    "    cleaned = \" \".join(cleaned.split())\n",
    "    \n",
    "    # 5. Restore the newlines (split/join removes them)\n",
    "    # A safer way to do step 4 while preserving newlines:\n",
    "    lines = [line.strip() for line in cleaned.split('\\n')]\n",
    "    cleaned = \"\\n\".join([l for l in lines if l]) # remove empty lines\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PROMPTING STRATEGIES (ENHANCED WITH CHART2TABLE)\n",
    "# ============================================================================\n",
    "\n",
    "class PromptingStrategies:\n",
    "    \"\"\"Implementation of different prompting strategies - Enhanced version with Chart2Table\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def baseline(question: str) -> str:\n",
    "        \"\"\"Strategy 1: Baseline with strict formatting constraints\"\"\"\n",
    "        return f\"\"\"Question: {question}\n",
    "        Answer the question using a single word or phrase.\n",
    "        End your response with: Final Answer: [your answer]\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def zero_shot_cot(question: str) -> str:\n",
    "        \"\"\"Strategy 2: Zero-Shot with Chain-of-Thought - Enhanced with calculation guidance\"\"\"\n",
    "        return f\"\"\"Question: {question}\n",
    "Let's solve this step by step with careful analysis and calculations.\n",
    "*IMPORTANT: Use digits (e.g., 3, 20.5) for all numbers, not words like 'three'.*\n",
    "*For arithmetic: Show each calculation step explicitly (e.g., 103.7 - 103.13 = 0.57)*\n",
    "1. Identify the chart type and analyze the axes and legend:\n",
    "2. Extract the relevant numbers/data from the chart:\n",
    "3. Determine what calculation or reasoning is needed:\n",
    "4. Perform the calculation or analysis step-by-step:\n",
    "5. Verify the answer makes sense:\n",
    "6. Final Answer:\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def few_shot_text(question: str) -> str:\n",
    "        \"\"\"Strategy 3: Few-Shot with 4 diverse examples\"\"\"\n",
    "        examples = \"\"\"Here are examples of chart analysis (use digits for all numbers):\n",
    "\n",
    "Example 1:\n",
    "Question: How many categories are shown in the bar chart?\n",
    "Analysis: Looking at the y-axis, I can count the distinct category labels. There are 5 bars, each representing one category.\n",
    "Answer: 5\n",
    "\n",
    "Example 2:\n",
    "Question: What is the value for Sales in Q2?\n",
    "Analysis: Looking at the bar chart, the Sales bar for Q2 reaches to 85 on the y-axis.\n",
    "Answer: 85\n",
    "\n",
    "Example 3:\n",
    "Question: What percentage does Marketing represent in the budget?\n",
    "Analysis: The pie chart shows the Marketing segment labeled as 25%. All segments sum to 100%.\n",
    "Answer: 25%\n",
    "\n",
    "Example 4:\n",
    "Question: What is the difference between the highest and lowest values?\n",
    "Analysis: The highest bar reaches 150, and the lowest reaches 45. The difference is 150 - 45 = 105.\n",
    "Answer: 105\n",
    "\n",
    "Now analyze this chart:\n",
    "\"\"\"\n",
    "        return examples + f\"Question: {question}\\nAnalysis:\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def few_shot_multimodal(question: str, example_images: List[str] = None) -> tuple:\n",
    "        \"\"\"\n",
    "        Strategy 4: True Multimodal Few-Shot Prompting\n",
    "        Now with 3 examples: Bar Chart, Pie Chart, and Line Chart\n",
    "        \"\"\"\n",
    "        if example_images is None or len(example_images) < 3:\n",
    "            return (None, False)\n",
    "        \n",
    "        # Verify files exist\n",
    "        valid_images = [img for img in example_images if Path(img).exists()]\n",
    "        if len(valid_images) < 3:\n",
    "            print(f\"Warning: Expected 3 example images, found {len(valid_images)}. Skipping multimodal few-shot.\")\n",
    "            return (None, False)\n",
    "        \n",
    "        messages = []\n",
    "        \n",
    "        # Example 1: Bar Chart - Direct value reading\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": example_images[0]},\n",
    "                {\"type\": \"text\", \"text\": \"What was the production volume of diamonds in Angola in 2004?\"}\n",
    "            ]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Based on the bar chart, the volume for Angola in 2004 is 6.1.\\n\\nFinal Answer: 6.1\"\n",
    "        })\n",
    "        \n",
    "        # Example 2: Pie Chart - Calculation with multiple values\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": example_images[1]},\n",
    "                {\"type\": \"text\", \"text\": \"Take highest percentage and lowest percentage (leave 0), add it and divide it by 2, what is the result?\"}\n",
    "            ]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"From the pie chart, the highest percentage is 33% and the lowest non-zero percentage is 2%. The calculation is (33 + 2) / 2 = 35 / 2 = 17.5.\\n\\nFinal Answer: 17.5\"\n",
    "        })\n",
    "        \n",
    "        # Example 3: Line Chart - Time series difference\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": example_images[2]},\n",
    "                {\"type\": \"text\", \"text\": \"What is the difference in the percentage of livestock breeds classified as being at risk of extinction between 2002 and 2003?\"}\n",
    "            ]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Looking at the line chart for Thailand, the value in 2002 is approximately 10% and in 2003 is also approximately 9%. Reading more precisely from the chart, the difference is 10% - 9% = 1%. Converting to decimal form, this is 0.01.\\n\\nFinal Answer: 0.01\"\n",
    "        })\n",
    "            \n",
    "        return (messages, True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def structured_output(question: str) -> str:\n",
    "        \"\"\"Strategy 5: Structured Output with comprehensive JSON fields\"\"\"\n",
    "        return f\"\"\"You are a helpful assistant that analyzes charts.\n",
    "Analyze the chart to answer the user's question.\n",
    "Provide your answer only in the following JSON format.\n",
    "*IMPORTANT: Use digits (e.g., 3, 20.5) for all numbers, not words (e.g., 'three').*\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "json\n",
    "{{\n",
    "  \"chart_type\": \"description of chart type (bar, pie, line, etc.)\",\n",
    "  \"key_elements\": \"important elements observed (axes, legend, data points)\",\n",
    "  \"reasoning\": \"step-by-step reasoning to answer the question\",\n",
    "  \"answer\": \"the final answer to the question\",\n",
    "  \"confidence\": \"high/medium/low confidence in the answer\"\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def role_based(question: str) -> str:\n",
    "        \"\"\"Strategy 6: Role-Based Prompting with expert persona\"\"\"\n",
    "        return f\"\"\"You are an expert data analyst specializing in chart interpretation.\n",
    "Your task is to analyze the provided chart with precision and answer the user's question.\n",
    "*Guidelines: Use digits (e.g., 3, 20) for all numerical answers, not words (e.g., 'three').*\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Expert Analysis and Final Answer:\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def chart2table_chain(question: str, chart2table_table: str) -> str:\n",
    "        \"\"\"\n",
    "        Strategy 7: NEW - Chart2Table Chain-of-Models Approach\n",
    "        \n",
    "        This strategy uses extracted tabular data from Chart2Table model\n",
    "        along with the visual chart to provide comprehensive analysis.\n",
    "        \n",
    "        Args:\n",
    "            question: The question to answer\n",
    "            chart2table_table: Extracted table data from Chart2Table model\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced prompt with table context\n",
    "        \"\"\"\n",
    "        # CLEAN THE DATA FIRST\n",
    "        clean_table = chart2table_table\n",
    "\n",
    "        return f\"\"\"You are analyzing a chart to answer a question. \n",
    "To help you, a data extraction model has already extracted the underlying tabular data from this chart.\n",
    "\n",
    "*Extracted Table Data:*\n",
    "{clean_table}\n",
    "\n",
    "*Important Instructions:*\n",
    "1. Use BOTH the visual chart AND the extracted table data to answer accurately\n",
    "2. The table data provides exact numerical values - use them for precise calculations\n",
    "3. The visual chart helps you understand trends, patterns, and context\n",
    "4. Cross-verify information between the table and the chart\n",
    "5. Use digits (e.g., 3, 20.5) for all numbers in your answer, not words\n",
    "6. *CRITICAL:* End your response with \"Final Answer: X\" where X is ONLY the precise answer value (number, label, or brief phrase - no full sentences)\n",
    "\n",
    "*Question:* {question}\n",
    "\n",
    "*Your Analysis and Answer:*\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def chart2table_cot(question: str, chart2table_table: str) -> str:\n",
    "        \"\"\"\n",
    "        Strategy 8: NEW - Chart2Table Chain + Chain-of-Thought (Hybrid Approach)\n",
    "        \n",
    "        ✅ IMPLEMENTATION: This strategy combines the best of both worlds:\n",
    "        - Chart2Table provides exact numerical data from the chart\n",
    "        - Chain-of-Thought guides systematic reasoning and verification\n",
    "        \n",
    "        This hybrid approach should theoretically achieve the highest accuracy because:\n",
    "        1. Chart2Table eliminates OCR/visual reading errors for numerical values\n",
    "        2. CoT reduces calculation errors through step-by-step verification\n",
    "        3. Cross-referencing visual + tabular data catches inconsistencies\n",
    "        \n",
    "        Combines the strengths of:\n",
    "        - Chart2Table: Precise tabular data extraction\n",
    "        - Chain-of-Thought: Step-by-step reasoning and verification\n",
    "        \n",
    "        This strategy provides the model with exact numerical data while encouraging\n",
    "        systematic analysis and calculation verification.\n",
    "        \n",
    "        Args:\n",
    "            question: The question to answer\n",
    "            chart2table_table: Extracted table data from Chart2Table model (already cleaned)\n",
    "            \n",
    "        Returns:\n",
    "            Hybrid prompt with table context and CoT guidance\n",
    "        \"\"\"\n",
    "        \n",
    "        return f\"\"\"You are analyzing a chart to answer a question using both visual information and extracted data.\n",
    "\n",
    "*Extracted Table Data from Chart:*\n",
    "{chart2table_table}\n",
    "\n",
    "*Question:* {question}\n",
    "\n",
    "*Instructions:* Solve this step-by-step using BOTH the table data and the visual chart.\n",
    "\n",
    "*Step-by-Step Analysis:*\n",
    "\n",
    "1. *Understand the Question:*\n",
    "   - What is being asked?\n",
    "   - What specific information do I need to find?\n",
    "\n",
    "2. *Analyze the Chart Visually:*\n",
    "   - What type of chart is this? (bar, line, pie, etc.)\n",
    "   - What do the axes/legend represent?\n",
    "   - Are there any important visual patterns or trends?\n",
    "\n",
    "3. *Cross-Reference with Table Data:*\n",
    "   - Locate the relevant data points in the extracted table\n",
    "   - Verify these match what you see in the chart\n",
    "   - Identify the exact numerical values needed\n",
    "\n",
    "4. *Perform Calculations (if needed):*\n",
    "   - Show each calculation step explicitly\n",
    "   - Use the exact values from the table data\n",
    "   - Example format: 45.7 - 23.2 = 22.5\n",
    "   - *CRITICAL: Use digits (e.g., 5, 20.5) for all numbers, never words like 'five'*\n",
    "\n",
    "5. *Verify Your Answer:*\n",
    "   - Does the answer make sense given the chart context?\n",
    "   - Does it match both the visual representation and table data?\n",
    "   - Check your calculations for arithmetic errors\n",
    "\n",
    "6. *Provide Final Answer:*\n",
    "   - End with: Final Answer: [your answer]\n",
    "\n",
    "*Your Step-by-Step Solution:*\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# BENCHMARK DATASET CREATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_benchmark_dataset(output_path: str = \"benchmark.json\"):\n",
    "    \"\"\"Create benchmark dataset from HuggingFaceM4/ChartQA\"\"\"\n",
    "    print(\"Creating benchmark dataset from HuggingFaceM4/ChartQA...\")\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        # Load from test split\n",
    "        chartqa = load_dataset(\"HuggingFaceM4/ChartQA\", split=\"test\")\n",
    "        \n",
    "        benchmark = []\n",
    "        Path(\"benchmark_images\").mkdir(exist_ok=True)\n",
    "        \n",
    "        for idx, item in enumerate(chartqa):\n",
    "            image_path = f\"benchmark_images/chart_{idx}.png\"\n",
    "            item[\"image\"].save(image_path)\n",
    "            \n",
    "            benchmark.append({\n",
    "                \"id\": f\"chart_{idx}\",\n",
    "                \"image_path\": image_path,\n",
    "                \"question\": item[\"query\"],\n",
    "                \"answer\": item[\"label\"],\n",
    "                \"source\": \"HuggingFaceM4/ChartQA\"\n",
    "            })\n",
    "        \n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(benchmark, f, indent=2)\n",
    "        \n",
    "        print(f\"✅ Benchmark created with {len(benchmark)} examples\")\n",
    "        return benchmark\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating benchmark: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATION - CORRECTED VERSION WITH ALL CRITICAL FIXES\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_answer(predicted: str, ground_truth, max_relative_change: float = 0.05) -> bool:\n",
    "    \"\"\"\n",
    "    ULTIMATE evaluation function - Best of both worlds.\n",
    "    \n",
    "    Combines:\n",
    "    - Original's comprehensive normalization and pattern matching\n",
    "    - Robust's smart evaluation order and ALL-numbers checking\n",
    "    \n",
    "    Args:\n",
    "        predicted: Model's prediction (string)\n",
    "        ground_truth: Correct answer (string or list - ChartQA format)\n",
    "        max_relative_change: Relative tolerance (default 5% = 0.05)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if answer is correct within tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Handle ChartQA List Format\n",
    "    # ========================================================================\n",
    "    if isinstance(ground_truth, list):\n",
    "        if not ground_truth:\n",
    "            return False\n",
    "        gt_list = [str(g) for g in ground_truth]\n",
    "    else:\n",
    "        gt_list = [str(ground_truth)]\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: JSON Extraction\n",
    "    # ========================================================================\n",
    "    try:\n",
    "        json_match = re.search(r'json\\s*(\\{.*?\\})\\s*', predicted, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(1))\n",
    "            if \"answer\" in data:\n",
    "                predicted = str(data[\"answer\"])\n",
    "        elif predicted.strip().startswith(\"{\"):\n",
    "            data = json.loads(predicted)\n",
    "            if \"answer\" in data:\n",
    "                predicted = str(data[\"answer\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 3: Pattern Extraction - FINAL ROBUST VERSION\n",
    "    # ========================================================================\n",
    "    \n",
    "    # First, clean up escape sequences\n",
    "    predicted = predicted.replace('\\\\n', '\\n').replace('\\\\t', ' ')\n",
    "\n",
    "    # Extract answer using patterns (most specific to least specific)\n",
    "    # NOTE: We removed \\. and \\, from the stop condition to protect decimals!\n",
    "    answer_patterns = [\n",
    "        r'final\\s+answer\\s*:?\\s*is\\s*:?\\s*(.+?)(?:\\n|$)',  \n",
    "        r'final\\s+answer\\s*:?\\s*(.+?)(?:\\n|$)',            \n",
    "        r'the\\s+answer\\s+is\\s*:?\\s*(.+?)(?:\\n|$)',          \n",
    "        r'\\nanswer\\s*:\\s*(.+?)(?:\\n|$)',    # Newline + \"Answer:\" (Avoids verbs)\n",
    "        r'^answer\\s*:\\s*(.+?)(?:\\n|$)',     # Start of string + \"Answer:\"\n",
    "    ]\n",
    "\n",
    "    for pattern in answer_patterns:\n",
    "        # Use MULTILINE to handle ^ and \\n correctly\n",
    "        match = re.search(pattern, predicted, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            extracted = match.group(1).strip()\n",
    "            \n",
    "            # SMART CLEANUP (The \"Decimal Protector\"):\n",
    "            # Only split on punctuation if followed by space or end of line.\n",
    "            # This keeps \"0.57\" intact but cleans \"50.\"\n",
    "            extracted = re.split(r'[.,;](?:\\s|$)', extracted)[0].strip()\n",
    "            \n",
    "            # Remove any remaining weird leading punctuation\n",
    "            extracted = re.sub(r'^[\\s\\-=:*]+', '', extracted)\n",
    "            \n",
    "            # ✅ ADDED: Also remove trailing punctuation that survived\n",
    "            extracted = re.sub(r'[;!?]+$', '', extracted)\n",
    "            \n",
    "            if extracted and len(extracted) < 50:\n",
    "                predicted = extracted\n",
    "                break\n",
    "\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 4: Comprehensive Normalization\n",
    "    # ========================================================================\n",
    "    def normalize(text):\n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        # Comprehensive word-to-digit\n",
    "        word_to_digit = {\n",
    "            'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', \n",
    "            'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', \n",
    "            'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13', \n",
    "            'fourteen': '14', 'fifteen': '15', 'sixteen': '16', 'seventeen': '17',\n",
    "            'eighteen': '18', 'nineteen': '19', 'twenty': '20',\n",
    "            'thirty': '30', 'forty': '40', 'fifty': '50', 'sixty': '60',\n",
    "            'seventy': '70', 'eighty': '80', 'ninety': '90', 'hundred': '100'\n",
    "        }\n",
    "        \n",
    "        for word, digit in word_to_digit.items():\n",
    "            text = re.sub(r'\\b' + word + r'\\b', digit, text)\n",
    "        \n",
    "        # Remove currency symbols and commas\n",
    "        text = text.replace('$', '').replace('€', '').replace('£', '').replace(',', '')\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    pred_clean = normalize(predicted)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 5: Evaluate Against Each Ground Truth\n",
    "    # ========================================================================\n",
    "    for gt_item in gt_list:\n",
    "        gt_clean = normalize(gt_item)\n",
    "        \n",
    "        # Extract ALL numbers (handles negatives and decimals automatically)\n",
    "        pred_numbers = [float(x) for x in re.findall(r'-?\\d+\\.?\\d*', pred_clean)]\n",
    "        gt_numbers = [float(x) for x in re.findall(r'-?\\d+\\.?\\d*', gt_clean)]\n",
    "        \n",
    "        # CHECK 1: Exact String Match\n",
    "        if pred_clean == gt_clean:\n",
    "            return True\n",
    "        \n",
    "        # CHECK 2: Substring Match (ONLY for non-numeric GT)\n",
    "        if not gt_numbers:\n",
    "            if gt_clean in pred_clean:\n",
    "                return True\n",
    "        \n",
    "        # CHECK 3: Numerical Comparison (Check ALL numbers with better tolerance)\n",
    "        if gt_numbers:\n",
    "            target = gt_numbers[0]\n",
    "            \n",
    "            for candidate in pred_numbers:\n",
    "                # Exact match\n",
    "                if candidate == target:\n",
    "                    return True\n",
    "                \n",
    "                # Relative error (5%)\n",
    "                if target == 0:\n",
    "                    if abs(candidate) < 1e-6:\n",
    "                        return True\n",
    "                else:\n",
    "                    relative_error = abs(candidate - target) / abs(target)\n",
    "                    if relative_error <= max_relative_change:\n",
    "                        return True\n",
    "                    \n",
    "                    # Percentage mismatch (bidirectional)\n",
    "                    if abs(target) > 1 and abs(candidate) < 1:\n",
    "                        candidate_as_percentage = candidate * 100\n",
    "                        if abs(candidate_as_percentage - target) / abs(target) <= max_relative_change:\n",
    "                            return True\n",
    "                    \n",
    "                    if abs(target) < 1 and abs(candidate) > 1:\n",
    "                        candidate_as_decimal = candidate / 100\n",
    "                        if abs(candidate_as_decimal - target) / abs(target) <= max_relative_change:\n",
    "                            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# def evaluate_answer(predicted: str, ground_truth, max_relative_change: float = 0.05) -> bool:\n",
    "#     \"\"\"\n",
    "#     Enhanced evaluation function with critical bug fixes:\n",
    "#     - ✅ Handles ChartQA list format (CRITICAL FIX)\n",
    "#     - ✅ Uses 5% relative tolerance (ChartQA standard)\n",
    "#     - ✅ JSON parsing for structured outputs\n",
    "#     - ✅ Word-to-digit conversion\n",
    "#     - ✅ Currency and percentage symbol handling\n",
    "#     - ✅ Pattern extraction for verbose outputs\n",
    "    \n",
    "#     Args:\n",
    "#         predicted: Model's prediction (string)\n",
    "#         ground_truth: Correct answer (string or list - ChartQA format)\n",
    "#         max_relative_change: Relative tolerance (default 5% = 0.05)\n",
    "    \n",
    "#     Returns:\n",
    "#         bool: True if answer is correct within tolerance\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # CRITICAL FIX 1: Handle ChartQA List Format\n",
    "#     # ========================================================================\n",
    "#     if isinstance(ground_truth, list):\n",
    "#         if len(ground_truth) > 0:\n",
    "#             ground_truth = str(ground_truth[0])\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 1: JSON Extraction for Structured Outputs\n",
    "#     # ========================================================================\n",
    "#     try:\n",
    "#         # Check for code block format\n",
    "#         json_match = re.search(r'json\\s*(\\{.*?\\})\\s*', predicted, re.DOTALL)\n",
    "#         if json_match:\n",
    "#             json_str = json_match.group(1)\n",
    "#             data = json.loads(json_str)\n",
    "#             if \"answer\" in data:\n",
    "#                 predicted = str(data[\"answer\"])\n",
    "#         else:\n",
    "#             # Check if the whole string is JSON\n",
    "#             if predicted.strip().startswith(\"{\"):\n",
    "#                 data = json.loads(predicted)\n",
    "#                 if \"answer\" in data:\n",
    "#                     predicted = str(data[\"answer\"])\n",
    "#     except:\n",
    "#         pass  # If JSON parsing fails, proceed with raw text\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 2: Normalize and Apply Word-to-Digit Conversion\n",
    "#     # ========================================================================\n",
    "#     pred_norm = predicted.lower().strip()\n",
    "#     gt_norm = str(ground_truth).lower().strip()\n",
    "    \n",
    "#     # Word to Digit Conversion\n",
    "#     word_to_digit = {\n",
    "#         'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', \n",
    "#         'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', \n",
    "#         'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13', \n",
    "#         'fourteen': '14', 'fifteen': '15', 'sixteen': '16', 'seventeen': '17',\n",
    "#         'eighteen': '18', 'nineteen': '19', 'twenty': '20',\n",
    "#         'thirty': '30', 'forty': '40', 'fifty': '50', 'sixty': '60',\n",
    "#         'seventy': '70', 'eighty': '80', 'ninety': '90', 'hundred': '100'\n",
    "#     }\n",
    "    \n",
    "#     for word, digit in word_to_digit.items():\n",
    "#         pred_norm = re.sub(r'\\b' + word + r'\\b', digit, pred_norm)\n",
    "#         gt_norm = re.sub(r'\\b' + word + r'\\b', digit, gt_norm)\n",
    "    \n",
    "#     # Remove currency symbols and handle commas\n",
    "#     pred_norm = pred_norm.replace('$', '').replace('€', '').replace('£', '')\n",
    "#     pred_norm = pred_norm.replace(',', '')  # Handle 1,234 → 1234\n",
    "#     gt_norm = gt_norm.replace('$', '').replace('€', '').replace('£', '')\n",
    "#     gt_norm = gt_norm.replace(',', '')\n",
    "    \n",
    "#     # Clean punctuation (but keep . for decimals and % for percentages)\n",
    "#     pred_clean = re.sub(r'[^\\w\\s.%]', '', pred_norm)\n",
    "#     gt_clean = re.sub(r'[^\\w\\s.%]', '', gt_norm)\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 3: String Matching (Fast Path)\n",
    "#     # ========================================================================\n",
    "#     # Exact match\n",
    "#     if pred_clean == gt_clean:\n",
    "#         return True\n",
    "    \n",
    "#     # Substring match\n",
    "#     if gt_clean in pred_clean:\n",
    "#         return True\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # CRITICAL FIX 2: Use 5% Relative Tolerance (ChartQA Standard)\n",
    "#     # ========================================================================\n",
    "#     try:\n",
    "#         # Extract numbers (handles decimals and negatives)\n",
    "#         pred_numbers = re.findall(r'-?\\d+\\.?\\d*', pred_clean)\n",
    "#         gt_numbers = re.findall(r'-?\\d+\\.?\\d*', gt_clean)\n",
    "        \n",
    "#         if pred_numbers and gt_numbers:\n",
    "#             pred_num = float(pred_numbers[0])\n",
    "#             gt_num = float(gt_numbers[0])\n",
    "            \n",
    "#             # Special case: Zero\n",
    "#             if gt_num == 0:\n",
    "#                 if abs(pred_num) < 1e-6:\n",
    "#                     return True\n",
    "#             else:\n",
    "#                 # FIXED: Use 5% relative error instead of 1% absolute\n",
    "#                 relative_error = abs(pred_num - gt_num) / abs(gt_num)\n",
    "#                 if relative_error <= max_relative_change:\n",
    "#                     return True\n",
    "            \n",
    "#             # Handle percentage format mismatch (0.25 vs 25%)\n",
    "#             # Case 1: GT is percentage like \"25\", pred is decimal like \"0.25\"\n",
    "#             if gt_num > 1 and pred_num < 1:\n",
    "#                 pred_as_percentage = pred_num * 100\n",
    "#                 if gt_num != 0:\n",
    "#                     relative_error = abs(pred_as_percentage - gt_num) / abs(gt_num)\n",
    "#                     if relative_error <= max_relative_change:\n",
    "#                         return True\n",
    "            \n",
    "#             # Case 2: Pred is percentage like \"25\", GT is decimal like \"0.25\"\n",
    "#             if pred_num > 1 and gt_num < 1:\n",
    "#                 pred_as_decimal = pred_num / 100\n",
    "#                 if gt_num != 0:\n",
    "#                     relative_error = abs(pred_as_decimal - gt_num) / abs(gt_num)\n",
    "#                     if relative_error <= max_relative_change:\n",
    "#                         return True\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 4: Pattern Extraction for Verbose Outputs\n",
    "#     # ========================================================================\n",
    "#     answer_patterns = [\n",
    "#         r'final answer:?\\s+is:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#         r'final answer:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#         r'the answer is:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#         r'answer:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#     ]\n",
    "    \n",
    "#     for pattern in answer_patterns:\n",
    "#         match = re.search(pattern, pred_clean, re.IGNORECASE)\n",
    "#         if match:\n",
    "#             extracted = match.group(1).strip()\n",
    "            \n",
    "#             # Only use if extraction looks reasonable\n",
    "#             if extracted and len(extracted) < 100:\n",
    "#                 # Substring match on extracted answer\n",
    "#                 if gt_clean in extracted:\n",
    "#                     return True\n",
    "                \n",
    "#                 # Try numerical match on extracted answer\n",
    "#                 try:\n",
    "#                     extracted_numbers = re.findall(r'-?\\d+\\.?\\d*', extracted)\n",
    "#                     if extracted_numbers and gt_numbers:\n",
    "#                         extracted_num = float(extracted_numbers[0])\n",
    "#                         gt_num = float(gt_numbers[0])\n",
    "                        \n",
    "#                         if gt_num == 0:\n",
    "#                             if abs(extracted_num) < 1e-6:\n",
    "#                                 return True\n",
    "#                         else:\n",
    "#                             relative_error = abs(extracted_num - gt_num) / abs(gt_num)\n",
    "#                             if relative_error <= max_relative_change:\n",
    "#                                 return True\n",
    "                            \n",
    "#                             # Try percentage mismatch on extracted\n",
    "#                             if gt_num > 1 and extracted_num < 1:\n",
    "#                                 extracted_as_percentage = extracted_num * 100\n",
    "#                                 relative_error = abs(extracted_as_percentage - gt_num) / abs(gt_num)\n",
    "#                                 if relative_error <= max_relative_change:\n",
    "#                                     return True\n",
    "                            \n",
    "#                             if extracted_num > 1 and gt_num < 1:\n",
    "#                                 extracted_as_decimal = extracted_num / 100\n",
    "#                                 relative_error = abs(extracted_as_decimal - gt_num) / abs(gt_num)\n",
    "#                                 if relative_error <= max_relative_change:\n",
    "#                                     return True\n",
    "#                 except:\n",
    "#                     pass\n",
    "    \n",
    "#     return False\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION (ENHANCED WITH CHART2TABLE + STRATEGY SELECTION)\n",
    "# ============================================================================\n",
    "\n",
    "def run_comprehensive_evaluation(\n",
    "    analyzer, \n",
    "    benchmark, \n",
    "    num_samples=None,\n",
    "    output_file=\"results_merged.json\", \n",
    "    debug_mode=False,\n",
    "    use_chart2table=True,  # Enable/disable Chart2Table-based strategies\n",
    "    strategies_to_test=None  # List of specific strategies to test (None = all)\n",
    "):\n",
    "    \"\"\"\n",
    "    Run comprehensive evaluation of all prompting strategies\n",
    "    \n",
    "    Args:\n",
    "        analyzer: ChartAnalyzer instance\n",
    "        benchmark: List of benchmark examples\n",
    "        num_samples: Number of samples to test (None = all, or specify like 100)\n",
    "        output_file: Path to save results\n",
    "        debug_mode: If True, print detailed debug info\n",
    "        use_chart2table: If True, enable Chart2Table-based strategies\n",
    "        strategies_to_test: List of strategy names to test, e.g., [\"baseline\", \"chart2table_cot\"]\n",
    "                           If None, tests all strategies. Available options:\n",
    "                           - \"baseline\"\n",
    "                           - \"zero_shot_cot\"\n",
    "                           - \"few_shot_text\"\n",
    "                           - \"few_shot_multimodal\"\n",
    "                           - \"structured\"\n",
    "                           - \"role_based\"\n",
    "                           - \"chart2table_chain\" (requires use_chart2table=True)\n",
    "                           - \"chart2table_cot\" (NEW - requires use_chart2table=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Limit benchmark size if specified\n",
    "    if num_samples is not None:\n",
    "        benchmark = benchmark[:num_samples]\n",
    "        print(f\"Testing with {len(benchmark)} samples (limited from full dataset)\")\n",
    "    else:\n",
    "        print(f\"Testing with all {len(benchmark)} samples\")\n",
    "\n",
    "    # Build full strategies dictionary\n",
    "    # NOTE: Strategies execute in the order defined here\n",
    "    all_strategies = {}\n",
    "    \n",
    "    # Add Chart2Table-based strategies if enabled (prioritize them first)\n",
    "    if use_chart2table:\n",
    "        all_strategies[\"chart2table_chain\"] = PromptingStrategies.chart2table_chain\n",
    "        all_strategies[\"chart2table_cot\"] = PromptingStrategies.chart2table_cot  # NEW\n",
    "    \n",
    "    # Add remaining strategies in standard order\n",
    "    all_strategies.update({\n",
    "        \"baseline\": PromptingStrategies.baseline,\n",
    "        \"zero_shot_cot\": PromptingStrategies.zero_shot_cot,\n",
    "        \"few_shot_text\": PromptingStrategies.few_shot_text,\n",
    "        \"few_shot_multimodal\": PromptingStrategies.few_shot_multimodal,\n",
    "        \"structured\": PromptingStrategies.structured_output,\n",
    "        \"role_based\": PromptingStrategies.role_based\n",
    "    })\n",
    "    \n",
    "    # Filter strategies if specific ones requested\n",
    "    if strategies_to_test is not None:\n",
    "        # Validate requested strategies\n",
    "        invalid_strategies = [s for s in strategies_to_test if s not in all_strategies]\n",
    "        if invalid_strategies:\n",
    "            print(f\"⚠  Warning: Invalid strategies requested: {invalid_strategies}\")\n",
    "            print(f\"Available strategies: {list(all_strategies.keys())}\")\n",
    "        \n",
    "        strategies = {k: v for k, v in all_strategies.items() if k in strategies_to_test}\n",
    "        \n",
    "        if not strategies:\n",
    "            print(\"❌ Error: No valid strategies selected!\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n✅ Testing only these strategies: {list(strategies.keys())}\")\n",
    "    else:\n",
    "        strategies = all_strategies\n",
    "        print(f\"\\n✅ Testing all {len(strategies)} strategies\")\n",
    "    \n",
    "    # Example images for multimodal few-shot\n",
    "    multimodal_example_images = [\n",
    "        \"example_images/example_bar_chart.png\",\n",
    "        \"example_images/example_pie_chart.png\",\n",
    "        \"example_images/example_line_chart.png\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize Chart2Table if needed\n",
    "    chart2table_extractor = None\n",
    "    if any(s in strategies for s in [\"chart2table_chain\", \"chart2table_cot\"]):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Initializing Chart2Table model for Chart2Table-based strategies...\")\n",
    "        print(\"=\"*60)\n",
    "        chart2table_extractor = ChartExtractor()\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing Strategy: {strategy_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        strategy_results = []\n",
    "        correct_count = 0\n",
    "        \n",
    "        for i, example in enumerate(tqdm(benchmark, desc=f\"{strategy_name}\")):\n",
    "            try:\n",
    "                prompt_text = \"\"\n",
    "                history = None\n",
    "                table_data = None  # Store for debug output\n",
    "                \n",
    "                # Handle different strategies\n",
    "                if strategy_name == \"few_shot_multimodal\":\n",
    "                    hist, ok = strategy_func(example[\"question\"], multimodal_example_images)\n",
    "                    if not ok:\n",
    "                        strategy_results.append({\n",
    "                            \"id\": example[\"id\"],\n",
    "                            \"question\": example[\"question\"],\n",
    "                            \"error\": \"Multimodal example images not found\"\n",
    "                        })\n",
    "                        continue\n",
    "                    history = hist\n",
    "                    prompt_text = example[\"question\"]\n",
    "                \n",
    "                elif strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "                    # ✅ Chart2Table-based strategies (chain and CoT hybrid)\n",
    "                    # Step 1: Extract table data using Chart2Table\n",
    "                    chart2table_start = time.time()\n",
    "                    \n",
    "                    raw_table_data = chart2table_extractor.extract_table(example[\"image_path\"])\n",
    "                    # ✅ Clean the table data IMMEDIATELY\n",
    "                    table_data = clean_chart2text_output(raw_table_data)\n",
    "\n",
    "                    chart2table_time = time.time() - chart2table_start\n",
    "                    \n",
    "                    # Step 2: Create enhanced prompt with table data\n",
    "                    prompt_text = strategy_func(example[\"question\"], table_data)\n",
    "                    \n",
    "                    # Note: Chart2Table info will be added to result_entry below\n",
    "                \n",
    "                else:\n",
    "                    prompt_text = strategy_func(example[\"question\"])\n",
    "                \n",
    "                # Generate response\n",
    "                start = time.time()\n",
    "                response = analyzer.generate_response(\n",
    "                    image_path=example[\"image_path\"],\n",
    "                    prompt=prompt_text,\n",
    "                    few_shot_messages=history\n",
    "                )\n",
    "                inference_time = time.time() - start\n",
    "                \n",
    "                # Evaluate\n",
    "                is_correct = evaluate_answer(response, example[\"answer\"])\n",
    "                if is_correct:\n",
    "                    correct_count += 1\n",
    "                \n",
    "                # Update results\n",
    "                result_entry = {\n",
    "                    \"id\": example[\"id\"],\n",
    "                    \"question\": example[\"question\"],\n",
    "                    \"predicted\": response,\n",
    "                    \"ground_truth\": example[\"answer\"],\n",
    "                    \"correct\": is_correct,\n",
    "                    \"inference_time\": inference_time\n",
    "                }\n",
    "                \n",
    "                # ✅ Add Chart2Table-specific info for both strategies\n",
    "                if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "                    result_entry[\"chart2table_extraction_time\"] = chart2table_time\n",
    "                    result_entry[\"total_time\"] = inference_time + chart2table_time\n",
    "                    result_entry[\"extracted_table\"] = table_data[:200] + \"...\" if len(table_data) > 200 else table_data\n",
    "                \n",
    "                strategy_results.append(result_entry)\n",
    "                \n",
    "                # Debug mode: print first 3 examples\n",
    "                if debug_mode and i < 3:\n",
    "                    print(f\"\\n--- Example {i + 1} ---\")\n",
    "                    print(f\"Question: {example['question']}\")\n",
    "                    if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"] and table_data:\n",
    "                        print(f\"Chart2Table Table: {table_data[:150]}...\")\n",
    "                    print(f\"Predicted: {response}\")\n",
    "                    print(f\"Ground Truth: {example['answer']}\")\n",
    "                    print(f\"Correct: {is_correct}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError on {example['id']}: {e}\")\n",
    "                if debug_mode:\n",
    "                    traceback.print_exc()\n",
    "                strategy_results.append({\n",
    "                    \"id\": example[\"id\"],\n",
    "                    \"question\": example[\"question\"],\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_valid = len([r for r in strategy_results if \"error\" not in r and \"question\" in r])\n",
    "        if total_valid > 0:\n",
    "            accuracy = correct_count / total_valid\n",
    "            avg_time = np.mean([r.get(\"inference_time\", 0) for r in strategy_results if \"inference_time\" in r])\n",
    "            \n",
    "            # Calculate total time for Chart2Table-based strategies\n",
    "            if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "                avg_total_time = np.mean([r.get(\"total_time\", 0) for r in strategy_results if \"total_time\" in r])\n",
    "            else:\n",
    "                avg_total_time = 0\n",
    "        else:\n",
    "            accuracy = 0\n",
    "            avg_time = 0\n",
    "            avg_total_time = 0\n",
    "        \n",
    "        all_results[strategy_name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"correct_count\": correct_count,\n",
    "            \"total\": total_valid,\n",
    "            \"avg_inference_time\": avg_time,\n",
    "            \"results\": strategy_results\n",
    "        }\n",
    "        \n",
    "        # Add total time for Chart2Table-based strategies\n",
    "        if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "            all_results[strategy_name][\"avg_total_time\"] = avg_total_time\n",
    "        \n",
    "        print(f\"\\nResults for {strategy_name}:\")\n",
    "        print(f\"  Accuracy: {accuracy:.2%} ({correct_count}/{total_valid})\")\n",
    "        print(f\"  Avg Inference Time: {avg_time:.2f}s\")\n",
    "        if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "            print(f\"  Avg Total Time (Chart2Table + Qwen): {avg_total_time:.2f}s\")\n",
    "    \n",
    "    # Save results\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for strategy_name, results in all_results.items():\n",
    "        print(f\"{strategy_name:20s}: {results['accuracy']:.2%}\")\n",
    "    \n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Chart Understanding with Qwen2.5-VL-7B-Instruct\")\n",
    "    print(\"ENHANCED VERSION - With Chart2Table Chain Strategy\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CONFIGURATION: Modify these parameters as needed\n",
    "    # ========================================================================\n",
    "    NUM_SAMPLES = None   # Set to 50 for testing, None for full dataset\n",
    "    DEBUG_MODE = True   # Set to True to see first 3 examples per strategy\n",
    "    USE_CHART2TABLE = True   # Set to True to enable Chart2Table chain strategy\n",
    "    OUTPUT_FILE = \"results_whole_with_chart2table.json\"  # results_whole_samples.json\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STRATEGY SELECTION: Choose which strategies to test\n",
    "    # ========================================================================\n",
    "    # Option 1: Test ALL strategies (default)\n",
    "    # STRATEGIES_TO_TEST = None\n",
    "    \n",
    "    # Option 2: Test only specific strategies (uncomment to use)\n",
    "    STRATEGIES_TO_TEST = [\"chart2table_cot\", \"chart2table_chain\"]\n",
    "    # STRATEGIES_TO_TEST = [\"chart2table_chain\"]  # Only Chart2Table\n",
    "    # STRATEGIES_TO_TEST = [\"baseline\", \"zero_shot_cot\", \"chart2table_chain\"]\n",
    "    \n",
    "    # Available strategies:\n",
    "    # - \"baseline\"\n",
    "    # - \"zero_shot_cot\"\n",
    "    # - \"few_shot_text\"\n",
    "    # - \"few_shot_multimodal\"\n",
    "    # - \"structured\"\n",
    "    # - \"role_based\"\n",
    "    # - \"chart2table_chain\" (requires USE_CHART2TABLE=True)\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Step 1: Initialize model\n",
    "    print(\"\\n[1/3] Initializing Qwen model...\")\n",
    "    analyzer = ChartAnalyzer()\n",
    "    \n",
    "    # Step 2: Create or load benchmark\n",
    "    print(\"\\n[2/3] Loading benchmark dataset...\")\n",
    "    if Path(\"benchmark.json\").exists():\n",
    "        with open(\"benchmark.json\", \"r\") as f:\n",
    "            benchmark = json.load(f)\n",
    "        print(f\"Loaded existing benchmark with {len(benchmark)} examples\")\n",
    "    else:\n",
    "        benchmark = create_benchmark_dataset()\n",
    "        if benchmark is None:\n",
    "            print(\"Failed to create benchmark. Please check the error above.\")\n",
    "            return\n",
    "    \n",
    "    # Step 3: Run evaluation\n",
    "    print(\"\\n[3/3] Running comprehensive evaluation...\")\n",
    "    results = run_comprehensive_evaluation(\n",
    "        analyzer,\n",
    "        benchmark,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        output_file=OUTPUT_FILE,\n",
    "        debug_mode=DEBUG_MODE,\n",
    "        use_chart2table=USE_CHART2TABLE,\n",
    "        strategies_to_test=STRATEGIES_TO_TEST\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Evaluation complete!\")\n",
    "    print(f\"Check '{OUTPUT_FILE}' for detailed results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3490d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same code as the above this cell directly except using the plotqa dataset\n",
    "### change also the evaluation function to handle dots at the end of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ffa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Chart Understanding with Qwen2.5-VL-7B-Instruct\n",
      "ENHANCED VERSION - With Chart2Table Chain Strategy\n",
      "============================================================\n",
      "\n",
      "[1/3] Initializing Qwen model...\n",
      "Loading model: Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:11<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "[2/3] Loading benchmark dataset (PlotQA train split)...\n",
      "Loaded existing benchmark with 2500 examples\n",
      "\n",
      "[3/3] Running comprehensive evaluation...\n",
      "Testing with all 2500 samples\n",
      "\n",
      "✅ Testing only these strategies: ['chart2table_cot', 'zero_shot_cot']\n",
      "\n",
      "============================================================\n",
      "Initializing Chart2Table model for Chart2Table-based strategies...\n",
      "============================================================\n",
      "Initializing Chart Extractor (PaddlePaddle API Client)...\n",
      "✓ Connected to PaddlePaddle API at http://localhost:8000\n",
      "  Response: {'status': 'healthy', 'service': 'PaddlePaddle Chart2Table API'}\n",
      "\n",
      "============================================================\n",
      "Testing Strategy: CHART2TABLE_COT\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot:   0%|          | 1/2500 [00:09<6:22:38,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1 ---\n",
      "Question: Are the number of bars on each tick of the Y-axis equal?\n",
      "Your response must be concise.\n",
      "Chart2Table Table: Year | Female | Male 1974 | 0.9 | 1.1 2000 | 0.5 | 0.5...\n",
      "Predicted: 1. **Understand the Question:**\n",
      "   - The question asks if the number of bars on each tick of the Y-axis is equal.\n",
      "   - This requires checking if there are two bars per year in the chart.\n",
      "\n",
      "2. **Analyze the Chart Visually:**\n",
      "   - The chart is a horizontal bar chart.\n",
      "   - The X-axis represents the percentage of children under 5.\n",
      "   - The Y-axis has two ticks labeled \"2000\" and \"1974\".\n",
      "   - Each tick has two bars: one for females and one for males.\n",
      "\n",
      "3. **Cross-Reference with Table Data:**\n",
      "   - From the table, we have:\n",
      "     - For 2000: Female = 0.5, Male = 0.5\n",
      "     - For 1974: Female = 0.9, Male = 1.1\n",
      "   - These values match the heights of the bars in the chart.\n",
      "\n",
      "4. **Perform Calculations (if needed):**\n",
      "   - No calculations are necessary as the question is about the number of bars, not their values.\n",
      "\n",
      "5. **Verify Your Answer:**\n",
      "   - Both years (2000 and 1974) have exactly two bars each.\n",
      "   - The visual confirmation matches the table data.\n",
      "\n",
      "6. **Provide Final Answer:**\n",
      "   - Final Answer: Yes, the number of bars on each tick of the Y-axis is equal.\n",
      "Ground Truth: Yes.\n",
      "Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot:   0%|          | 2/2500 [00:17<6:07:26,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 2 ---\n",
      "Question: How many bars are there on the 2nd tick from the top?\n",
      "Your answer should be compact.\n",
      "Chart2Table Table: Year | Female | Male 1974 | 0.9 | 1.1 2000 | 0.5 | 0.5...\n",
      "Predicted: 1. **Understand the Question:**\n",
      "   - The question asks how many bars are present on the second tick from the top.\n",
      "   - This refers to the year 1974 in the chart.\n",
      "\n",
      "2. **Analyze the Chart Visually:**\n",
      "   - The chart is a horizontal bar chart.\n",
      "   - The x-axis represents the percentage of children under 5 years old.\n",
      "   - The y-axis represents the years, with two ticks: 2000 and 1974.\n",
      "   - Each year has two bars corresponding to \"Female\" and \"Male.\"\n",
      "\n",
      "3. **Cross-Reference with Table Data:**\n",
      "   - For 1974, the table shows:\n",
      "     - Female: 0.9%\n",
      "     - Male: 1.1%\n",
      "   - These percentages correspond to the lengths of the bars in the chart.\n",
      "\n",
      "4. **Perform Calculations (if needed):**\n",
      "   - No calculations are necessary as we are simply counting the bars.\n",
      "\n",
      "5. **Verify Your Answer:**\n",
      "   - The chart clearly shows two bars for each year.\n",
      "   - For 1974, there are two bars: one for \"Female\" and one for \"Male.\"\n",
      "   - The table data confirms this with two distinct values.\n",
      "\n",
      "6. **Provide Final Answer:**\n",
      "   - Final Answer: 2\n",
      "Ground Truth: 2.\n",
      "Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot:   0%|          | 3/2500 [00:26<6:00:11,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 3 ---\n",
      "Question: How many bars are there on the 1st tick from the bottom?\n",
      "Keep it short and to the point.\n",
      "Chart2Table Table: Year | Female | Male 1974 | 0.9 | 1.1 2000 | 0.5 | 0.5...\n",
      "Predicted: 1. **Understand the Question:**\n",
      "   - The question asks how many bars are present on the first tick from the bottom.\n",
      "   - This corresponds to the year 1974 in the chart.\n",
      "\n",
      "2. **Analyze the Chart Visually:**\n",
      "   - The chart is a horizontal bar chart.\n",
      "   - The x-axis represents the percentage of children under 5.\n",
      "   - The y-axis represents the years.\n",
      "   - There are two bars for each year: one for females and one for males.\n",
      "   - For 1974, there are two bars visible.\n",
      "\n",
      "3. **Cross-Reference with Table Data:**\n",
      "   - From the table, we have:\n",
      "     - Year 1974: Female = 0.9%, Male = 1.1%\n",
      "   - These percentages correspond to the lengths of the bars in the chart.\n",
      "\n",
      "4. **Perform Calculations (if needed):**\n",
      "   - No calculations are necessary as the number of bars is visually clear.\n",
      "\n",
      "5. **Verify Your Answer:**\n",
      "   - The chart shows two bars for 1974, one for females and one for males.\n",
      "   - The table data confirms the presence of two bars for 1974.\n",
      "\n",
      "6. **Provide Final Answer:**\n",
      "   - Final Answer: 2\n",
      "Ground Truth: 2.\n",
      "Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chart2table_cot:  16%|█▋        | 407/2500 [1:27:08<9:33:51, 16.45s/it] "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Chart Understanding with Qwen2.5-VL-7B-Instruct\n",
    "Graduation Project - Prompting Techniques Evaluation\n",
    "ENHANCED VERSION: Added Chart2Table Chain-of-Models Strategy + Strategy Selection\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# QUICK CONFIGURATION - Modify these before running!\n",
    "# ============================================================================\n",
    "# To test with 100 examples: Set NUM_SAMPLES = 100\n",
    "# To test with full dataset: Set NUM_SAMPLES = None\n",
    "# See main() function for more configuration options\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "import base64\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\n",
    "from qwen_vl_utils import process_vision_info  # REQUIRED: pip install qwen-vl-utils\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "class Config:\n",
    "\n",
    "    # GPU Memory Management\n",
    "    GPU_MEMORY_FRACTION = 0.75  # Use 75% of remaining GPU memory\n",
    "    ENABLE_TF32 = True  # Faster computation on Ampere+ GPUs\n",
    "\n",
    "    # LLM (PyTorch - same as before)\n",
    "    LLM_MODEL = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "    DATASET = \"jrc/cleaned-plotqa-v2\"\n",
    "    OUTPUT_DIR = \"plotqa_safe_solver_cot_sc_v2\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # PaddlePaddle API Server (microservice)\n",
    "    PADDLE_API_URL = \"http://localhost:8000\"  # Change if running on different machine\n",
    "    PADDLE_API_TIMEOUT = 30  # seconds\n",
    "\n",
    "    # Token limits\n",
    "    MAX_INPUT_TOKENS = 4096\n",
    "    MAX_NEW_TOKENS = 128\n",
    "\n",
    "    # CoT + Self-Consistency\n",
    "    USE_COT = True\n",
    "    FEW_SHOT_COT = True\n",
    "    SC_SAMPLES = 5\n",
    "    TEMP_COT = 0.7\n",
    "    TOP_P_COT = 0.95\n",
    "\n",
    "    # Debug\n",
    "    VERBOSE_DEBUG = False\n",
    "\n",
    "# ================================================================\n",
    "# CHART EXTRACTOR: CALLS PADDLEPADDLE API INSTEAD OF LOCAL MODEL\n",
    "# ================================================================\n",
    "\n",
    "class ChartExtractor:\n",
    "    \"\"\"Client for PaddlePaddle Chart2Table API\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Initializing Chart Extractor (PaddlePaddle API Client)...\")\n",
    "        self.api_url = Config.PADDLE_API_URL\n",
    "        self.timeout = Config.PADDLE_API_TIMEOUT\n",
    "        \n",
    "        # Check if API is available\n",
    "        try:\n",
    "            response = requests.get(f\"{self.api_url}/health\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"✓ Connected to PaddlePaddle API at {self.api_url}\")\n",
    "                print(f\"  Response: {response.json()}\")\n",
    "            else:\n",
    "                raise Exception(f\"API returned status {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to connect to PaddlePaddle API at {self.api_url}\")\n",
    "            print(f\"  Error: {e}\")\n",
    "            print(f\"  Make sure the API server is running:\")\n",
    "            print(f\"    uvicorn paddle_api_server:app --host 0.0.0.0 --port 8000\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def extract_table(self, image_input) -> str:\n",
    "        \"\"\"Extract table from image by calling the PaddlePaddle API\n",
    "        \n",
    "        Args:\n",
    "            image_input: Either a PIL Image object or a string path to image file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ✅ Handle both PIL Image and string path\n",
    "            if isinstance(image_input, str):\n",
    "                from PIL import Image\n",
    "                image = Image.open(image_input)\n",
    "            else:\n",
    "                image = image_input\n",
    "            \n",
    "            # Convert image to base64\n",
    "            img_buffer = io.BytesIO()\n",
    "            image.save(img_buffer, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(img_buffer.getvalue()).decode(\"utf-8\")\n",
    "            \n",
    "            # Call API\n",
    "            response = requests.post(\n",
    "                f\"{self.api_url}/extract-base64\",\n",
    "                json={\"image_base64\": img_base64},\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                raise Exception(f\"API error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "            result = response.json()\n",
    "            \n",
    "            if not result.get(\"success\"):\n",
    "                raise Exception(f\"API returned failure: {result}\")\n",
    "            \n",
    "            # Return cleaned table\n",
    "            return result[\"table_clean\"]\n",
    "        \n",
    "        except requests.exceptions.Timeout:\n",
    "            raise Exception(f\"API request timed out (>{self.timeout}s). Check server status.\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            raise Exception(f\"Cannot connect to PaddlePaddle API at {self.api_url}. Is server running?\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error extracting chart: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL SETUP (FROM FIRST CODE - CORRECT IMPLEMENTATION)\n",
    "# ============================================================================\n",
    "\n",
    "class ChartAnalyzer:\n",
    "    \"\"\"Main class for chart analysis using Qwen2.5-VL-7B-Instruct\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = \"Qwen/Qwen2.5-VL-7B-Instruct\"):\n",
    "        print(f\"Loading model: {model_path}\")\n",
    "        \n",
    "        # ✅ NEW: Limit GPU memory usage BEFORE loading model\n",
    "        # Set GPU memory fraction\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.set_per_process_memory_fraction(Config.GPU_MEMORY_FRACTION, 0)\n",
    "            # Enable TF32 for faster computation (Ampere+ GPUs)\n",
    "            if Config.ENABLE_TF32:\n",
    "                torch.backends.cuda.matmul.allow_tf32 = True\n",
    "                torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "        # Load model\n",
    "        self.model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        # Load processor\n",
    "        self.processor = AutoProcessor.from_pretrained(\n",
    "            model_path,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        \n",
    "    def generate_response(\n",
    "        self, \n",
    "        image_path: str, \n",
    "        prompt: str,\n",
    "        max_new_tokens: int = 512,\n",
    "        temperature: float = 0.1,  # Lower temperature for factual chart tasks\n",
    "        top_p: float = 0.9,\n",
    "        few_shot_messages: List[Dict] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate response for a given image and prompt\n",
    "        Uses official Qwen implementation with qwen_vl_utils\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the chart image\n",
    "            prompt: Text prompt for the model\n",
    "            max_new_tokens: Maximum tokens to generate\n",
    "            temperature: Sampling temperature (lower = more factual)\n",
    "            top_p: Top-p sampling parameter\n",
    "            few_shot_messages: Optional pre-built message history for multimodal few-shot\n",
    "            \n",
    "        Returns:\n",
    "            Generated text response\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Construct Messages\n",
    "        messages = []\n",
    "        \n",
    "        # Add few-shot history if present\n",
    "        if few_shot_messages:\n",
    "            messages.extend(few_shot_messages)\n",
    "            \n",
    "        # Add current query\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image_path},  # CORRECT: use 'image' key\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        # 2. Prepare Inputs (The Official Qwen Way)\n",
    "        text = self.processor.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        \n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Move inputs to GPU\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        \n",
    "        # 3. Generate\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                do_sample=temperature > 0\n",
    "            )\n",
    "        \n",
    "        # 4. Decode - Trim input tokens from output\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        \n",
    "        response_text = self.processor.batch_decode(\n",
    "            generated_ids_trimmed, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "        \n",
    "        return response_text\n",
    "\n",
    "\n",
    "def clean_chart2text_output(table_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans raw Chart2Table output into a readable format for the LLM.\n",
    "    \"\"\"\n",
    "    # 1. Replace the hex newline with a real newline\n",
    "    cleaned = table_text.replace(\"<0x0A>\", \"\\n\")\n",
    "    \n",
    "    # 2. Replace hex tab with a pipe (if it exists)\n",
    "    cleaned = cleaned.replace(\"<0x09>\", \" | \")\n",
    "    \n",
    "    # 3. Ensure pipes have spaces for better tokenization\n",
    "    # This handles cases like \"Apple|5\" becoming \"Apple | 5\"\n",
    "    cleaned = cleaned.replace(\"|\", \" | \")\n",
    "    \n",
    "    # 4. Remove multiple spaces created by step 3\n",
    "    # (e.g., if it was already \" | \", step 3 makes it \"  |  \")\n",
    "    cleaned = \" \".join(cleaned.split())\n",
    "    \n",
    "    # 5. Restore the newlines (split/join removes them)\n",
    "    # A safer way to do step 4 while preserving newlines:\n",
    "    lines = [line.strip() for line in cleaned.split('\\n')]\n",
    "    cleaned = \"\\n\".join([l for l in lines if l]) # remove empty lines\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PROMPTING STRATEGIES (ENHANCED WITH CHART2TABLE)\n",
    "# ============================================================================\n",
    "\n",
    "class PromptingStrategies:\n",
    "    \"\"\"Implementation of different prompting strategies - Enhanced version with Chart2Table\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def baseline(question: str) -> str:\n",
    "        \"\"\"Strategy 1: Baseline with strict formatting constraints\"\"\"\n",
    "        return f\"\"\"Question: {question}\n",
    "        Answer the question using a single word or phrase.\n",
    "        End your response with: Final Answer: [your answer]\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def zero_shot_cot(question: str) -> str:\n",
    "        \"\"\"Strategy 2: Zero-Shot with Chain-of-Thought - Enhanced with calculation guidance\"\"\"\n",
    "        return f\"\"\"Question: {question}\n",
    "Let's solve this step by step with careful analysis and calculations.\n",
    "*IMPORTANT: Use digits (e.g., 3, 20.5) for all numbers, not words like 'three'.*\n",
    "*For arithmetic: Show each calculation step explicitly (e.g., 103.7 - 103.13 = 0.57)*\n",
    "1. Identify the chart type and analyze the axes and legend:\n",
    "2. Extract the relevant numbers/data from the chart:\n",
    "3. Determine what calculation or reasoning is needed:\n",
    "4. Perform the calculation or analysis step-by-step:\n",
    "5. Verify the answer makes sense:\n",
    "6. Final Answer:\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def few_shot_text(question: str) -> str:\n",
    "        \"\"\"Strategy 3: Few-Shot with 4 diverse examples\"\"\"\n",
    "        examples = \"\"\"Here are examples of chart analysis (use digits for all numbers):\n",
    "\n",
    "Example 1:\n",
    "Question: How many categories are shown in the bar chart?\n",
    "Analysis: Looking at the y-axis, I can count the distinct category labels. There are 5 bars, each representing one category.\n",
    "Answer: 5\n",
    "\n",
    "Example 2:\n",
    "Question: What is the value for Sales in Q2?\n",
    "Analysis: Looking at the bar chart, the Sales bar for Q2 reaches to 85 on the y-axis.\n",
    "Answer: 85\n",
    "\n",
    "Example 3:\n",
    "Question: What percentage does Marketing represent in the budget?\n",
    "Analysis: The pie chart shows the Marketing segment labeled as 25%. All segments sum to 100%.\n",
    "Answer: 25%\n",
    "\n",
    "Example 4:\n",
    "Question: What is the difference between the highest and lowest values?\n",
    "Analysis: The highest bar reaches 150, and the lowest reaches 45. The difference is 150 - 45 = 105.\n",
    "Answer: 105\n",
    "\n",
    "Now analyze this chart:\n",
    "\"\"\"\n",
    "        return examples + f\"Question: {question}\\nAnalysis:\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def few_shot_multimodal(question: str, example_images: List[str] = None) -> tuple:\n",
    "        \"\"\"\n",
    "        Strategy 4: True Multimodal Few-Shot Prompting\n",
    "        Now with 3 examples: Bar Chart, Pie Chart, and Line Chart\n",
    "        \"\"\"\n",
    "        if example_images is None or len(example_images) < 3:\n",
    "            return (None, False)\n",
    "        \n",
    "        # Verify files exist\n",
    "        valid_images = [img for img in example_images if Path(img).exists()]\n",
    "        if len(valid_images) < 3:\n",
    "            print(f\"Warning: Expected 3 example images, found {len(valid_images)}. Skipping multimodal few-shot.\")\n",
    "            return (None, False)\n",
    "        \n",
    "        messages = []\n",
    "        \n",
    "        # Example 1: Bar Chart - Direct value reading\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": example_images[0]},\n",
    "                {\"type\": \"text\", \"text\": \"What was the production volume of diamonds in Angola in 2004?\"}\n",
    "            ]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Based on the bar chart, the volume for Angola in 2004 is 6.1.\\n\\nFinal Answer: 6.1\"\n",
    "        })\n",
    "        \n",
    "        # Example 2: Pie Chart - Calculation with multiple values\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": example_images[1]},\n",
    "                {\"type\": \"text\", \"text\": \"Take highest percentage and lowest percentage (leave 0), add it and divide it by 2, what is the result?\"}\n",
    "            ]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"From the pie chart, the highest percentage is 33% and the lowest non-zero percentage is 2%. The calculation is (33 + 2) / 2 = 35 / 2 = 17.5.\\n\\nFinal Answer: 17.5\"\n",
    "        })\n",
    "        \n",
    "        # Example 3: Line Chart - Time series difference\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": example_images[2]},\n",
    "                {\"type\": \"text\", \"text\": \"What is the difference in the percentage of livestock breeds classified as being at risk of extinction between 2002 and 2003?\"}\n",
    "            ]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Looking at the line chart for Thailand, the value in 2002 is approximately 10% and in 2003 is also approximately 9%. Reading more precisely from the chart, the difference is 10% - 9% = 1%. Converting to decimal form, this is 0.01.\\n\\nFinal Answer: 0.01\"\n",
    "        })\n",
    "            \n",
    "        return (messages, True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def structured_output(question: str) -> str:\n",
    "        \"\"\"Strategy 5: Structured Output with comprehensive JSON fields\"\"\"\n",
    "        return f\"\"\"You are a helpful assistant that analyzes charts.\n",
    "Analyze the chart to answer the user's question.\n",
    "Provide your answer only in the following JSON format.\n",
    "*IMPORTANT: Use digits (e.g., 3, 20.5) for all numbers, not words (e.g., 'three').*\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "json\n",
    "{{\n",
    "  \"chart_type\": \"description of chart type (bar, pie, line, etc.)\",\n",
    "  \"key_elements\": \"important elements observed (axes, legend, data points)\",\n",
    "  \"reasoning\": \"step-by-step reasoning to answer the question\",\n",
    "  \"answer\": \"the final answer to the question\",\n",
    "  \"confidence\": \"high/medium/low confidence in the answer\"\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def role_based(question: str) -> str:\n",
    "        \"\"\"Strategy 6: Role-Based Prompting with expert persona\"\"\"\n",
    "        return f\"\"\"You are an expert data analyst specializing in chart interpretation.\n",
    "Your task is to analyze the provided chart with precision and answer the user's question.\n",
    "*Guidelines: Use digits (e.g., 3, 20) for all numerical answers, not words (e.g., 'three').*\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Expert Analysis and Final Answer:\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def chart2table_chain(question: str, chart2table_table: str) -> str:\n",
    "        \"\"\"\n",
    "        Strategy 7: NEW - Chart2Table Chain-of-Models Approach\n",
    "        \n",
    "        This strategy uses extracted tabular data from Chart2Table model\n",
    "        along with the visual chart to provide comprehensive analysis.\n",
    "        \n",
    "        Args:\n",
    "            question: The question to answer\n",
    "            chart2table_table: Extracted table data from Chart2Table model\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced prompt with table context\n",
    "        \"\"\"\n",
    "        # CLEAN THE DATA FIRST\n",
    "        clean_table = chart2table_table\n",
    "\n",
    "        return f\"\"\"You are analyzing a chart to answer a question. \n",
    "To help you, a data extraction model has already extracted the underlying tabular data from this chart.\n",
    "\n",
    "*Extracted Table Data:*\n",
    "{clean_table}\n",
    "\n",
    "*Important Instructions:*\n",
    "1. Use BOTH the visual chart AND the extracted table data to answer accurately\n",
    "2. The table data provides exact numerical values - use them for precise calculations\n",
    "3. The visual chart helps you understand trends, patterns, and context\n",
    "4. Cross-verify information between the table and the chart\n",
    "5. Use digits (e.g., 3, 20.5) for all numbers in your answer, not words\n",
    "6. *CRITICAL:* End your response with \"Final Answer: X\" where X is ONLY the precise answer value (number, label, or brief phrase - no full sentences)\n",
    "\n",
    "*Question:* {question}\n",
    "\n",
    "*Your Analysis and Answer:*\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def chart2table_cot(question: str, chart2table_table: str) -> str:\n",
    "        \"\"\"\n",
    "        Strategy 8: NEW - Chart2Table Chain + Chain-of-Thought (Hybrid Approach)\n",
    "        \n",
    "        ✅ IMPLEMENTATION: This strategy combines the best of both worlds:\n",
    "        - Chart2Table provides exact numerical data from the chart\n",
    "        - Chain-of-Thought guides systematic reasoning and verification\n",
    "        \n",
    "        This hybrid approach should theoretically achieve the highest accuracy because:\n",
    "        1. Chart2Table eliminates OCR/visual reading errors for numerical values\n",
    "        2. CoT reduces calculation errors through step-by-step verification\n",
    "        3. Cross-referencing visual + tabular data catches inconsistencies\n",
    "        \n",
    "        Combines the strengths of:\n",
    "        - Chart2Table: Precise tabular data extraction\n",
    "        - Chain-of-Thought: Step-by-step reasoning and verification\n",
    "        \n",
    "        This strategy provides the model with exact numerical data while encouraging\n",
    "        systematic analysis and calculation verification.\n",
    "        \n",
    "        Args:\n",
    "            question: The question to answer\n",
    "            chart2table_table: Extracted table data from Chart2Table model (already cleaned)\n",
    "            \n",
    "        Returns:\n",
    "            Hybrid prompt with table context and CoT guidance\n",
    "        \"\"\"\n",
    "        \n",
    "        return f\"\"\"You are analyzing a chart to answer a question using both visual information and extracted data.\n",
    "\n",
    "*Extracted Table Data from Chart:*\n",
    "{chart2table_table}\n",
    "\n",
    "*Question:* {question}\n",
    "\n",
    "*Instructions:* Solve this step-by-step using BOTH the table data and the visual chart.\n",
    "\n",
    "*Step-by-Step Analysis:*\n",
    "\n",
    "1. *Understand the Question:*\n",
    "   - What is being asked?\n",
    "   - What specific information do I need to find?\n",
    "\n",
    "2. *Analyze the Chart Visually:*\n",
    "   - What type of chart is this? (bar, line, pie, etc.)\n",
    "   - What do the axes/legend represent?\n",
    "   - Are there any important visual patterns or trends?\n",
    "\n",
    "3. *Cross-Reference with Table Data:*\n",
    "   - Locate the relevant data points in the extracted table\n",
    "   - Verify these match what you see in the chart\n",
    "   - Identify the exact numerical values needed\n",
    "\n",
    "4. *Perform Calculations (if needed):*\n",
    "   - Show each calculation step explicitly\n",
    "   - Use the exact values from the table data\n",
    "   - Example format: 45.7 - 23.2 = 22.5\n",
    "   - *CRITICAL: Use digits (e.g., 5, 20.5) for all numbers, never words like 'five'*\n",
    "\n",
    "5. *Verify Your Answer:*\n",
    "   - Does the answer make sense given the chart context?\n",
    "   - Does it match both the visual representation and table data?\n",
    "   - Check your calculations for arithmetic errors\n",
    "\n",
    "6. *Provide Final Answer:*\n",
    "   - End with: Final Answer: [your answer]\n",
    "\n",
    "*Your Step-by-Step Solution:*\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# BENCHMARK DATASET CREATION - MODIFIED FOR PLOTQA\n",
    "# ============================================================================\n",
    "\n",
    "def create_benchmark_dataset(output_path: str = \"benchmark_plotqa.json\", split: str = \"train\", max_samples: int = 2500):\n",
    "    \"\"\"\n",
    "    Create benchmark dataset from PlotQA dataset (jrc/cleaned-plotqa-v2)\n",
    "    \n",
    "    MODIFIED FOR PLOTQA:\n",
    "    - Uses \"jrc/cleaned-plotqa-v2\" dataset\n",
    "    - Handles PlotQA column names: 'image', 'question_string', 'answer_string'\n",
    "    - Saves images to benchmark_images_plotqa directory\n",
    "    \n",
    "    Args:\n",
    "        output_path: Path to save the benchmark JSON\n",
    "        split: Dataset split to use (\"train\", \"validation\", or \"test\")\n",
    "    \"\"\"\n",
    "    print(f\"Creating benchmark dataset from PlotQA (jrc/cleaned-plotqa-v2) - {split} split...\")\n",
    "    print(f\"Limiting to {max_samples} samples to save time and space\")\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        \n",
    "        # Load PlotQA dataset\n",
    "        plotqa = load_dataset(\"jrc/cleaned-plotqa-v2\", split=split, streaming=True)\n",
    "        \n",
    "        benchmark = []\n",
    "        images_dir = Path(\"benchmark_images_plotqa\")\n",
    "        images_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Use iterator and limit to max_samples\n",
    "        print(f\"Downloading and processing {max_samples} examples...\")\n",
    "        for idx, item in enumerate(tqdm(plotqa, total=max_samples, desc=\"Processing samples\")):\n",
    "            if idx >= max_samples:\n",
    "                break\n",
    "            # Save image\n",
    "            image_path = str(images_dir / f\"chart_{idx}.png\")\n",
    "            item[\"image\"].save(image_path)\n",
    "            \n",
    "            # PlotQA uses different column names\n",
    "            benchmark.append({\n",
    "                \"id\": f\"plotqa_{split}_{idx}\",\n",
    "                \"image_path\": image_path,\n",
    "                \"question\": item[\"user\"],  # PlotQA column name\n",
    "                \"answer\": item[\"assistant\"],      # PlotQA column name\n",
    "                \"source\": f\"jrc/cleaned-plotqa-v2 ({split})\"\n",
    "            })\n",
    "        \n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(benchmark, f, indent=2)\n",
    "        \n",
    "        print(f\"✅ Benchmark created with {len(benchmark)} examples from PlotQA {split} split\")\n",
    "        print(f\"   Images saved to: {images_dir}/\")\n",
    "        print(f\"   Benchmark saved to: {output_path}\")\n",
    "        return benchmark\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating benchmark: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATION - CORRECTED VERSION WITH ALL CRITICAL FIXES\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_answer(predicted: str, ground_truth, max_relative_change: float = 0.05) -> bool:\n",
    "    \"\"\"\n",
    "    ULTIMATE evaluation function - Best of both worlds.\n",
    "    \n",
    "    Combines:\n",
    "    - Original's comprehensive normalization and pattern matching\n",
    "    - Robust's smart evaluation order and ALL-numbers checking\n",
    "    \n",
    "    Args:\n",
    "        predicted: Model's prediction (string)\n",
    "        ground_truth: Correct answer (string or list - ChartQA/PlotQA format)\n",
    "        max_relative_change: Relative tolerance (default 5% = 0.05)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if answer is correct within tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Handle List Format (works for both ChartQA and PlotQA)\n",
    "    # ========================================================================\n",
    "    if isinstance(ground_truth, list):\n",
    "        if not ground_truth:\n",
    "            return False\n",
    "        gt_list = [str(g) for g in ground_truth]\n",
    "    else:\n",
    "        gt_list = [str(ground_truth)]\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: JSON Extraction\n",
    "    # ========================================================================\n",
    "    try:\n",
    "        json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', predicted, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(1))\n",
    "            if \"answer\" in data:\n",
    "                predicted = str(data[\"answer\"])\n",
    "        elif predicted.strip().startswith(\"{\"):\n",
    "            data = json.loads(predicted)\n",
    "            if \"answer\" in data:\n",
    "                predicted = str(data[\"answer\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 3: Pattern Extraction - FINAL ROBUST VERSION\n",
    "    # ========================================================================\n",
    "    \n",
    "    # First, clean up escape sequences\n",
    "    predicted = predicted.replace('\\\\n', '\\n').replace('\\\\t', ' ')\n",
    "\n",
    "    # Extract answer using patterns (most specific to least specific)\n",
    "    # NOTE: We removed \\. and \\, from the stop condition to protect decimals!\n",
    "    answer_patterns = [\n",
    "        r'final\\s+answer\\s*:?\\s*is\\s*:?\\s*(.+?)(?:\\n|$)',  \n",
    "        r'final\\s+answer\\s*:?\\s*(.+?)(?:\\n|$)',            \n",
    "        r'the\\s+answer\\s+is\\s*:?\\s*(.+?)(?:\\n|$)',          \n",
    "        r'\\nanswer\\s*:\\s*(.+?)(?:\\n|$)',    # Newline + \"Answer:\" (Avoids verbs)\n",
    "        r'^answer\\s*:\\s*(.+?)(?:\\n|$)',     # Start of string + \"Answer:\"\n",
    "    ]\n",
    "\n",
    "    for pattern in answer_patterns:\n",
    "        # Use MULTILINE to handle ^ and \\n correctly\n",
    "        match = re.search(pattern, predicted, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            extracted = match.group(1).strip()\n",
    "            \n",
    "            # SMART CLEANUP (The \"Decimal Protector\"):\n",
    "            # Only split on punctuation if followed by space or end of line.\n",
    "            # This keeps \"0.57\" intact but cleans \"50.\"\n",
    "            extracted = re.split(r'[.,;](?:\\s|$)', extracted)[0].strip()\n",
    "            \n",
    "            # Remove any remaining weird leading punctuation\n",
    "            extracted = re.sub(r'^[\\s\\-=:*]+', '', extracted)\n",
    "            \n",
    "            # ✅ ADDED: Also remove trailing punctuation that survived\n",
    "            extracted = re.sub(r'[;!?]+$', '', extracted)\n",
    "            \n",
    "            if extracted and len(extracted) < 250:\n",
    "                predicted = extracted\n",
    "                break\n",
    "\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 4: Comprehensive Normalization\n",
    "    # ========================================================================\n",
    "    def normalize(text):\n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        # Comprehensive word-to-digit\n",
    "        word_to_digit = {\n",
    "            'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', \n",
    "            'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', \n",
    "            'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13', \n",
    "            'fourteen': '14', 'fifteen': '15', 'sixteen': '16', 'seventeen': '17',\n",
    "            'eighteen': '18', 'nineteen': '19', 'twenty': '20',\n",
    "            'thirty': '30', 'forty': '40', 'fifty': '50', 'sixty': '60',\n",
    "            'seventy': '70', 'eighty': '80', 'ninety': '90', 'hundred': '100'\n",
    "        }\n",
    "        \n",
    "        for word, digit in word_to_digit.items():\n",
    "            text = re.sub(r'\\b' + word + r'\\b', digit, text)\n",
    "        \n",
    "        # Remove currency symbols and commas\n",
    "        text = text.replace('$', '').replace('€', '').replace('£', '').replace(',', '')\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        # ✅ CRITICAL FIX: Strip trailing punctuation from Ground Truth\n",
    "        # This allows \"Yes\" to match \"Yes.\"\n",
    "        text = text.rstrip('.,;!')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    pred_clean = normalize(predicted)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 5: Evaluate Against Each Ground Truth\n",
    "    # ========================================================================\n",
    "    for gt_item in gt_list:\n",
    "        gt_clean = normalize(gt_item)\n",
    "        \n",
    "        # Extract ALL numbers (handles negatives and decimals automatically)\n",
    "        pred_numbers = [float(x) for x in re.findall(r'-?\\d+\\.?\\d*', pred_clean)]\n",
    "        gt_numbers = [float(x) for x in re.findall(r'-?\\d+\\.?\\d*', gt_clean)]\n",
    "        \n",
    "        # CHECK 1: Exact String Match\n",
    "        if pred_clean == gt_clean:\n",
    "            return True\n",
    "        \n",
    "        # CHECK 2: Substring Match (ONLY for non-numeric GT)\n",
    "        if not gt_numbers:\n",
    "            if gt_clean in pred_clean or pred_clean in gt_clean:\n",
    "                return True\n",
    "        \n",
    "        # CHECK 3: Numerical Comparison (Check ALL numbers with better tolerance)\n",
    "        if gt_numbers:\n",
    "            target = gt_numbers[0]\n",
    "            \n",
    "            for candidate in pred_numbers:\n",
    "                # Exact match\n",
    "                if candidate == target:\n",
    "                    return True\n",
    "                \n",
    "                # Relative error (5%)\n",
    "                if target == 0:\n",
    "                    if abs(candidate) < 1e-6:\n",
    "                        return True\n",
    "                else:\n",
    "                    relative_error = abs(candidate - target) / abs(target)\n",
    "                    if relative_error <= max_relative_change:\n",
    "                        return True\n",
    "                    \n",
    "                    # Percentage mismatch (bidirectional)\n",
    "                    if abs(target) > 1 and abs(candidate) < 1:\n",
    "                        candidate_as_percentage = candidate * 100\n",
    "                        if abs(candidate_as_percentage - target) / abs(target) <= max_relative_change:\n",
    "                            return True\n",
    "                    \n",
    "                    if abs(target) < 1 and abs(candidate) > 1:\n",
    "                        candidate_as_decimal = candidate / 100\n",
    "                        if abs(candidate_as_decimal - target) / abs(target) <= max_relative_change:\n",
    "                            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "# def evaluate_answer(predicted: str, ground_truth, max_relative_change: float = 0.05) -> bool:\n",
    "#     \"\"\"\n",
    "#     Enhanced evaluation function with critical bug fixes:\n",
    "#     - ✅ Handles ChartQA list format (CRITICAL FIX)\n",
    "#     - ✅ Uses 5% relative tolerance (ChartQA standard)\n",
    "#     - ✅ JSON parsing for structured outputs\n",
    "#     - ✅ Word-to-digit conversion\n",
    "#     - ✅ Currency and percentage symbol handling\n",
    "#     - ✅ Pattern extraction for verbose outputs\n",
    "    \n",
    "#     Args:\n",
    "#         predicted: Model's prediction (string)\n",
    "#         ground_truth: Correct answer (string or list - ChartQA format)\n",
    "#         max_relative_change: Relative tolerance (default 5% = 0.05)\n",
    "    \n",
    "#     Returns:\n",
    "#         bool: True if answer is correct within tolerance\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # CRITICAL FIX 1: Handle ChartQA List Format\n",
    "#     # ========================================================================\n",
    "#     if isinstance(ground_truth, list):\n",
    "#         if len(ground_truth) > 0:\n",
    "#             ground_truth = str(ground_truth[0])\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 1: JSON Extraction for Structured Outputs\n",
    "#     # ========================================================================\n",
    "#     try:\n",
    "#         # Check for code block format\n",
    "#         json_match = re.search(r'json\\s*(\\{.*?\\})\\s*', predicted, re.DOTALL)\n",
    "#         if json_match:\n",
    "#             json_str = json_match.group(1)\n",
    "#             data = json.loads(json_str)\n",
    "#             if \"answer\" in data:\n",
    "#                 predicted = str(data[\"answer\"])\n",
    "#         else:\n",
    "#             # Check if the whole string is JSON\n",
    "#             if predicted.strip().startswith(\"{\"):\n",
    "#                 data = json.loads(predicted)\n",
    "#                 if \"answer\" in data:\n",
    "#                     predicted = str(data[\"answer\"])\n",
    "#     except:\n",
    "#         pass  # If JSON parsing fails, proceed with raw text\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 2: Normalize and Apply Word-to-Digit Conversion\n",
    "#     # ========================================================================\n",
    "#     pred_norm = predicted.lower().strip()\n",
    "#     gt_norm = str(ground_truth).lower().strip()\n",
    "    \n",
    "#     # Word to Digit Conversion\n",
    "#     word_to_digit = {\n",
    "#         'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', \n",
    "#         'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', \n",
    "#         'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13', \n",
    "#         'fourteen': '14', 'fifteen': '15', 'sixteen': '16', 'seventeen': '17',\n",
    "#         'eighteen': '18', 'nineteen': '19', 'twenty': '20',\n",
    "#         'thirty': '30', 'forty': '40', 'fifty': '50', 'sixty': '60',\n",
    "#         'seventy': '70', 'eighty': '80', 'ninety': '90', 'hundred': '100'\n",
    "#     }\n",
    "    \n",
    "#     for word, digit in word_to_digit.items():\n",
    "#         pred_norm = re.sub(r'\\b' + word + r'\\b', digit, pred_norm)\n",
    "#         gt_norm = re.sub(r'\\b' + word + r'\\b', digit, gt_norm)\n",
    "    \n",
    "#     # Remove currency symbols and handle commas\n",
    "#     pred_norm = pred_norm.replace('$', '').replace('€', '').replace('£', '')\n",
    "#     pred_norm = pred_norm.replace(',', '')  # Handle 1,234 → 1234\n",
    "#     gt_norm = gt_norm.replace('$', '').replace('€', '').replace('£', '')\n",
    "#     gt_norm = gt_norm.replace(',', '')\n",
    "    \n",
    "#     # Clean punctuation (but keep . for decimals and % for percentages)\n",
    "#     pred_clean = re.sub(r'[^\\w\\s.%]', '', pred_norm)\n",
    "#     gt_clean = re.sub(r'[^\\w\\s.%]', '', gt_norm)\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 3: String Matching (Fast Path)\n",
    "#     # ========================================================================\n",
    "#     # Exact match\n",
    "#     if pred_clean == gt_clean:\n",
    "#         return True\n",
    "    \n",
    "#     # Substring match\n",
    "#     if gt_clean in pred_clean:\n",
    "#         return True\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # CRITICAL FIX 2: Use 5% Relative Tolerance (ChartQA Standard)\n",
    "#     # ========================================================================\n",
    "#     try:\n",
    "#         # Extract numbers (handles decimals and negatives)\n",
    "#         pred_numbers = re.findall(r'-?\\d+\\.?\\d*', pred_clean)\n",
    "#         gt_numbers = re.findall(r'-?\\d+\\.?\\d*', gt_clean)\n",
    "        \n",
    "#         if pred_numbers and gt_numbers:\n",
    "#             pred_num = float(pred_numbers[0])\n",
    "#             gt_num = float(gt_numbers[0])\n",
    "            \n",
    "#             # Special case: Zero\n",
    "#             if gt_num == 0:\n",
    "#                 if abs(pred_num) < 1e-6:\n",
    "#                     return True\n",
    "#             else:\n",
    "#                 # FIXED: Use 5% relative error instead of 1% absolute\n",
    "#                 relative_error = abs(pred_num - gt_num) / abs(gt_num)\n",
    "#                 if relative_error <= max_relative_change:\n",
    "#                     return True\n",
    "            \n",
    "#             # Handle percentage format mismatch (0.25 vs 25%)\n",
    "#             # Case 1: GT is percentage like \"25\", pred is decimal like \"0.25\"\n",
    "#             if gt_num > 1 and pred_num < 1:\n",
    "#                 pred_as_percentage = pred_num * 100\n",
    "#                 if gt_num != 0:\n",
    "#                     relative_error = abs(pred_as_percentage - gt_num) / abs(gt_num)\n",
    "#                     if relative_error <= max_relative_change:\n",
    "#                         return True\n",
    "            \n",
    "#             # Case 2: Pred is percentage like \"25\", GT is decimal like \"0.25\"\n",
    "#             if pred_num > 1 and gt_num < 1:\n",
    "#                 pred_as_decimal = pred_num / 100\n",
    "#                 if gt_num != 0:\n",
    "#                     relative_error = abs(pred_as_decimal - gt_num) / abs(gt_num)\n",
    "#                     if relative_error <= max_relative_change:\n",
    "#                         return True\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # ========================================================================\n",
    "#     # STEP 4: Pattern Extraction for Verbose Outputs\n",
    "#     # ========================================================================\n",
    "#     answer_patterns = [\n",
    "#         r'final answer:?\\s+is:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#         r'final answer:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#         r'the answer is:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#         r'answer:?\\s*(.+?)(?:\\n|\\.|\\,|$)',\n",
    "#     ]\n",
    "    \n",
    "#     for pattern in answer_patterns:\n",
    "#         match = re.search(pattern, pred_clean, re.IGNORECASE)\n",
    "#         if match:\n",
    "#             extracted = match.group(1).strip()\n",
    "            \n",
    "#             # Only use if extraction looks reasonable\n",
    "#             if extracted and len(extracted) < 100:\n",
    "#                 # Substring match on extracted answer\n",
    "#                 if gt_clean in extracted:\n",
    "#                     return True\n",
    "                \n",
    "#                 # Try numerical match on extracted answer\n",
    "#                 try:\n",
    "#                     extracted_numbers = re.findall(r'-?\\d+\\.?\\d*', extracted)\n",
    "#                     if extracted_numbers and gt_numbers:\n",
    "#                         extracted_num = float(extracted_numbers[0])\n",
    "#                         gt_num = float(gt_numbers[0])\n",
    "                        \n",
    "#                         if gt_num == 0:\n",
    "#                             if abs(extracted_num) < 1e-6:\n",
    "#                                 return True\n",
    "#                         else:\n",
    "#                             relative_error = abs(extracted_num - gt_num) / abs(gt_num)\n",
    "#                             if relative_error <= max_relative_change:\n",
    "#                                 return True\n",
    "                            \n",
    "#                             # Try percentage mismatch on extracted\n",
    "#                             if gt_num > 1 and extracted_num < 1:\n",
    "#                                 extracted_as_percentage = extracted_num * 100\n",
    "#                                 relative_error = abs(extracted_as_percentage - gt_num) / abs(gt_num)\n",
    "#                                 if relative_error <= max_relative_change:\n",
    "#                                     return True\n",
    "                            \n",
    "#                             if extracted_num > 1 and gt_num < 1:\n",
    "#                                 extracted_as_decimal = extracted_num / 100\n",
    "#                                 relative_error = abs(extracted_as_decimal - gt_num) / abs(gt_num)\n",
    "#                                 if relative_error <= max_relative_change:\n",
    "#                                     return True\n",
    "#                 except:\n",
    "#                     pass\n",
    "    \n",
    "#     return False\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION (ENHANCED WITH CHART2TABLE + STRATEGY SELECTION)\n",
    "# ============================================================================\n",
    "\n",
    "def run_comprehensive_evaluation(\n",
    "    analyzer, \n",
    "    benchmark, \n",
    "    num_samples=None,\n",
    "    output_file=\"results_merged.json\", \n",
    "    debug_mode=False,\n",
    "    use_chart2table=True,  # Enable/disable Chart2Table-based strategies\n",
    "    strategies_to_test=None  # List of specific strategies to test (None = all)\n",
    "):\n",
    "    \"\"\"\n",
    "    Run comprehensive evaluation of all prompting strategies\n",
    "    \n",
    "    Args:\n",
    "        analyzer: ChartAnalyzer instance\n",
    "        benchmark: List of benchmark examples\n",
    "        num_samples: Number of samples to test (None = all, or specify like 100)\n",
    "        output_file: Path to save results\n",
    "        debug_mode: If True, print detailed debug info\n",
    "        use_chart2table: If True, enable Chart2Table-based strategies\n",
    "        strategies_to_test: List of strategy names to test, e.g., [\"baseline\", \"chart2table_cot\"]\n",
    "                           If None, tests all strategies. Available options:\n",
    "                           - \"baseline\"\n",
    "                           - \"zero_shot_cot\"\n",
    "                           - \"few_shot_text\"\n",
    "                           - \"few_shot_multimodal\"\n",
    "                           - \"structured\"\n",
    "                           - \"role_based\"\n",
    "                           - \"chart2table_chain\" (requires use_chart2table=True)\n",
    "                           - \"chart2table_cot\" (NEW - requires use_chart2table=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Limit benchmark size if specified\n",
    "    if num_samples is not None:\n",
    "        benchmark = benchmark[:num_samples]\n",
    "        print(f\"Testing with {len(benchmark)} samples (limited from full dataset)\")\n",
    "    else:\n",
    "        print(f\"Testing with all {len(benchmark)} samples\")\n",
    "\n",
    "    # Build full strategies dictionary\n",
    "    # NOTE: Strategies execute in the order defined here\n",
    "    all_strategies = {}\n",
    "    \n",
    "    # Add Chart2Table-based strategies if enabled (prioritize them first)\n",
    "    if use_chart2table:\n",
    "        all_strategies[\"chart2table_chain\"] = PromptingStrategies.chart2table_chain\n",
    "        all_strategies[\"chart2table_cot\"] = PromptingStrategies.chart2table_cot  # NEW\n",
    "    \n",
    "    # Add remaining strategies in standard order\n",
    "    all_strategies.update({\n",
    "        \"baseline\": PromptingStrategies.baseline,\n",
    "        \"zero_shot_cot\": PromptingStrategies.zero_shot_cot,\n",
    "        \"few_shot_text\": PromptingStrategies.few_shot_text,\n",
    "        \"few_shot_multimodal\": PromptingStrategies.few_shot_multimodal,\n",
    "        \"structured\": PromptingStrategies.structured_output,\n",
    "        \"role_based\": PromptingStrategies.role_based\n",
    "    })\n",
    "    \n",
    "    # Filter strategies if specific ones requested\n",
    "    if strategies_to_test is not None:\n",
    "        # Validate requested strategies\n",
    "        invalid_strategies = [s for s in strategies_to_test if s not in all_strategies]\n",
    "        if invalid_strategies:\n",
    "            print(f\"⚠  Warning: Invalid strategies requested: {invalid_strategies}\")\n",
    "            print(f\"Available strategies: {list(all_strategies.keys())}\")\n",
    "        \n",
    "        strategies = {k: v for k, v in all_strategies.items() if k in strategies_to_test}\n",
    "        \n",
    "        if not strategies:\n",
    "            print(\"❌ Error: No valid strategies selected!\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n✅ Testing only these strategies: {list(strategies.keys())}\")\n",
    "    else:\n",
    "        strategies = all_strategies\n",
    "        print(f\"\\n✅ Testing all {len(strategies)} strategies\")\n",
    "    \n",
    "    # Example images for multimodal few-shot\n",
    "    multimodal_example_images = [\n",
    "        \"example_images/example_bar_chart.png\",\n",
    "        \"example_images/example_pie_chart.png\",\n",
    "        \"example_images/example_line_chart.png\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize Chart2Table if needed\n",
    "    chart2table_extractor = None\n",
    "    if any(s in strategies for s in [\"chart2table_chain\", \"chart2table_cot\"]):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Initializing Chart2Table model for Chart2Table-based strategies...\")\n",
    "        print(\"=\"*60)\n",
    "        chart2table_extractor = ChartExtractor()\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing Strategy: {strategy_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        strategy_results = []\n",
    "        correct_count = 0\n",
    "        \n",
    "        for i, example in enumerate(tqdm(benchmark, desc=f\"{strategy_name}\")):\n",
    "            try:\n",
    "                prompt_text = \"\"\n",
    "                history = None\n",
    "                table_data = None  # Store for debug output\n",
    "                \n",
    "                # Handle different strategies\n",
    "                if strategy_name == \"few_shot_multimodal\":\n",
    "                    hist, ok = strategy_func(example[\"question\"], multimodal_example_images)\n",
    "                    if not ok:\n",
    "                        strategy_results.append({\n",
    "                            \"id\": example[\"id\"],\n",
    "                            \"question\": example[\"question\"],\n",
    "                            \"error\": \"Multimodal example images not found\"\n",
    "                        })\n",
    "                        continue\n",
    "                    history = hist\n",
    "                    prompt_text = example[\"question\"]\n",
    "                \n",
    "                elif strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "                    # ✅ Chart2Table-based strategies (chain and CoT hybrid)\n",
    "                    # Step 1: Extract table data using Chart2Table\n",
    "                    chart2table_start = time.time()\n",
    "                    \n",
    "                    raw_table_data = chart2table_extractor.extract_table(example[\"image_path\"])\n",
    "                    # ✅ Clean the table data IMMEDIATELY\n",
    "                    table_data = clean_chart2text_output(raw_table_data)\n",
    "\n",
    "                    chart2table_time = time.time() - chart2table_start\n",
    "                    \n",
    "                    # Step 2: Create enhanced prompt with table data\n",
    "                    prompt_text = strategy_func(example[\"question\"], table_data)\n",
    "                    \n",
    "                    # Note: Chart2Table info will be added to result_entry below\n",
    "                \n",
    "                else:\n",
    "                    prompt_text = strategy_func(example[\"question\"])\n",
    "                \n",
    "                # Generate response\n",
    "                start = time.time()\n",
    "                response = analyzer.generate_response(\n",
    "                    image_path=example[\"image_path\"],\n",
    "                    prompt=prompt_text,\n",
    "                    few_shot_messages=history\n",
    "                )\n",
    "                inference_time = time.time() - start\n",
    "                \n",
    "                # Evaluate\n",
    "                is_correct = evaluate_answer(response, example[\"answer\"])\n",
    "                if is_correct:\n",
    "                    correct_count += 1\n",
    "                \n",
    "                # Update results\n",
    "                result_entry = {\n",
    "                    \"id\": example[\"id\"],\n",
    "                    \"question\": example[\"question\"],\n",
    "                    \"predicted\": response,\n",
    "                    \"ground_truth\": example[\"answer\"],\n",
    "                    \"correct\": is_correct,\n",
    "                    \"inference_time\": inference_time\n",
    "                }\n",
    "                \n",
    "                # ✅ Add Chart2Table-specific info for both strategies\n",
    "                if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "                    result_entry[\"chart2table_extraction_time\"] = chart2table_time\n",
    "                    result_entry[\"total_time\"] = inference_time + chart2table_time\n",
    "                    result_entry[\"extracted_table\"] = table_data[:200] + \"...\" if len(table_data) > 200 else table_data\n",
    "                \n",
    "                strategy_results.append(result_entry)\n",
    "                \n",
    "                # Debug mode: print first 3 examples\n",
    "                if debug_mode and i < 3:\n",
    "                    print(f\"\\n--- Example {i + 1} ---\")\n",
    "                    print(f\"Question: {example['question']}\")\n",
    "                    if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"] and table_data:\n",
    "                        print(f\"Chart2Table Table: {table_data[:150]}...\")\n",
    "                    print(f\"Predicted: {response}\")\n",
    "                    print(f\"Ground Truth: {example['answer']}\")\n",
    "                    print(f\"Correct: {is_correct}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError on {example['id']}: {e}\")\n",
    "                if debug_mode:\n",
    "                    traceback.print_exc()\n",
    "                strategy_results.append({\n",
    "                    \"id\": example[\"id\"],\n",
    "                    \"question\": example[\"question\"],\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_valid = len([r for r in strategy_results if \"error\" not in r and \"question\" in r])\n",
    "        if total_valid > 0:\n",
    "            accuracy = correct_count / total_valid\n",
    "            avg_time = np.mean([r.get(\"inference_time\", 0) for r in strategy_results if \"inference_time\" in r])\n",
    "            \n",
    "            # Calculate total time for Chart2Table-based strategies\n",
    "            if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "                avg_total_time = np.mean([r.get(\"total_time\", 0) for r in strategy_results if \"total_time\" in r])\n",
    "            else:\n",
    "                avg_total_time = 0\n",
    "        else:\n",
    "            accuracy = 0\n",
    "            avg_time = 0\n",
    "            avg_total_time = 0\n",
    "        \n",
    "        all_results[strategy_name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"correct_count\": correct_count,\n",
    "            \"total\": total_valid,\n",
    "            \"avg_inference_time\": avg_time,\n",
    "            \"results\": strategy_results\n",
    "        }\n",
    "        \n",
    "        # Add total time for Chart2Table-based strategies\n",
    "        if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "            all_results[strategy_name][\"avg_total_time\"] = avg_total_time\n",
    "        \n",
    "        print(f\"\\nResults for {strategy_name}:\")\n",
    "        print(f\"  Accuracy: {accuracy:.2%} ({correct_count}/{total_valid})\")\n",
    "        print(f\"  Avg Inference Time: {avg_time:.2f}s\")\n",
    "        if strategy_name in [\"chart2table_chain\", \"chart2table_cot\"]:\n",
    "            print(f\"  Avg Total Time (Chart2Table + Qwen): {avg_total_time:.2f}s\")\n",
    "    \n",
    "    # Save results\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for strategy_name, results in all_results.items():\n",
    "        print(f\"{strategy_name:20s}: {results['accuracy']:.2%}\")\n",
    "    \n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Chart Understanding with Qwen2.5-VL-7B-Instruct\")\n",
    "    print(\"ENHANCED VERSION - With Chart2Table Chain Strategy\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CONFIGURATION: Modify these parameters as needed\n",
    "    # ========================================================================\n",
    "    NUM_SAMPLES = None   # Set to 50 for testing, None for full dataset\n",
    "    DEBUG_MODE = True   # Set to True to see first 3 examples per strategy\n",
    "    USE_CHART2TABLE = True   # Set to True to enable Chart2Table chain strategy\n",
    "    OUTPUT_FILE = \"results_whole_plotqa.json\"\n",
    "    DATASET_SPLIT = \"train\"   # Options: \"train\", \"validation\", \"test\"\n",
    "    MAX_DATASET_SAMPLES = 2500  # Maximum samples to download from PlotQA (to avoid downloading entire large dataset)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STRATEGY SELECTION: Choose which strategies to test\n",
    "    # ========================================================================\n",
    "    # Option 1: Test ALL strategies (default)\n",
    "    # STRATEGIES_TO_TEST = None\n",
    "    \n",
    "    # Option 2: Test only specific strategies (uncomment to use)\n",
    "    STRATEGIES_TO_TEST = [\"chart2table_cot\", \"zero_shot_cot\"]  # Only the new hybrid strategy\n",
    "    # STRATEGIES_TO_TEST = [\"baseline\", \"chart2table_chain\"]\n",
    "    # STRATEGIES_TO_TEST = [\"chart2table_chain\"]  # Only Chart2Table\n",
    "    # STRATEGIES_TO_TEST = [\"baseline\", \"zero_shot_cot\", \"chart2table_chain\"]\n",
    "    \n",
    "    # Available strategies:\n",
    "    # - \"baseline\"\n",
    "    # - \"zero_shot_cot\"\n",
    "    # - \"few_shot_text\"\n",
    "    # - \"few_shot_multimodal\"\n",
    "    # - \"structured\"\n",
    "    # - \"role_based\"\n",
    "    # - \"chart2table_chain\" (requires USE_CHART2TABLE=True)\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Step 1: Initialize model\n",
    "    print(\"\\n[1/3] Initializing Qwen model...\")\n",
    "    analyzer = ChartAnalyzer()\n",
    "    \n",
    "    # Step 2: Create or load benchmark\n",
    "    print(f\"\\n[2/3] Loading benchmark dataset (PlotQA {DATASET_SPLIT} split)...\")\n",
    "    benchmark_file = f\"benchmark_plotqa_{DATASET_SPLIT}.json\"\n",
    "    \n",
    "    if Path(benchmark_file).exists():\n",
    "        with open(benchmark_file, \"r\") as f:\n",
    "            benchmark = json.load(f)\n",
    "        print(f\"Loaded existing benchmark with {len(benchmark)} examples\")\n",
    "    else:\n",
    "        benchmark = create_benchmark_dataset(\n",
    "            output_path=benchmark_file,\n",
    "            split=DATASET_SPLIT,\n",
    "            max_samples=MAX_DATASET_SAMPLES\n",
    "        )\n",
    "        if benchmark is None:\n",
    "            print(\"Failed to create benchmark. Please check the error above.\")\n",
    "            return\n",
    "    \n",
    "    # Step 3: Run evaluation\n",
    "    print(\"\\n[3/3] Running comprehensive evaluation...\")\n",
    "    results = run_comprehensive_evaluation(\n",
    "        analyzer,\n",
    "        benchmark,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        output_file=OUTPUT_FILE,\n",
    "        debug_mode=DEBUG_MODE,\n",
    "        use_chart2table=USE_CHART2TABLE,\n",
    "        strategies_to_test=STRATEGIES_TO_TEST\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Evaluation complete!\")\n",
    "    print(f\"Check '{OUTPUT_FILE}' for detailed results.\")\n",
    "\n",
    "    # Print final comparison if multiple strategies tested\n",
    "    if results and len(results) > 1:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STRATEGY COMPARISON\")\n",
    "        print(\"=\"*60)\n",
    "        sorted_results = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
    "        print(f\"{'Strategy':<20} {'Accuracy':<12} {'Correct/Total':<15} {'Avg Time'}\")\n",
    "        print(\"-\"*60)\n",
    "        for name, res in sorted_results:\n",
    "            time_str = f\"{res['avg_total_time']:.2f}s\" if 'avg_total_time' in res else f\"{res['avg_inference_time']:.2f}s\"\n",
    "            print(f\"{name:<20} {res['accuracy']:>6.2%}      {res['correct_count']:>3}/{res['total']:<7}     {time_str}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c630815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
